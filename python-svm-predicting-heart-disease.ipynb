{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3464c5a-292b-4d55-8b77-cb96ca4ee520",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Predicting Heart Disease Using a Support Vector Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8edfa1-15b4-47d1-afca-da4ff9bc526c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1. Introduction:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fedac9-46dc-4a8f-9ef9-77a94ff82dd8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Background:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666906f8-a14d-4c5c-a39a-30dcee6e25f1",
   "metadata": {},
   "source": [
    "The purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0dbab3-3245-44fc-9511-a9cdf68b34de",
   "metadata": {},
   "source": [
    "### Objective:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489dca9b-4c24-4dd6-9120-012e25abf145",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd3f3a2f-b066-426f-b816-961eb0c052f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895f57d5-388c-4f71-a325-0207fed845a2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88489e0a-db6b-4256-abd9-a6c185dadaec",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tech Stack:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427f8eac-8640-4e39-867f-92bbfa06f7a6",
   "metadata": {},
   "source": [
    "The following tools and libraries are used in this project:\n",
    "- Python\n",
    "- Pandas\n",
    "- Matplotlib\n",
    "- Statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b8b95c-6465-4bc4-a7cc-ad819852715a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Setup and Imports:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c524ccb8-5050-4436-b8d6-dc423d64cc3c",
   "metadata": {},
   "source": [
    "### Library Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15eff0c-a346-4d0c-96cb-33906c7723f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statistics import mean\n",
    "\n",
    "# Scipy and Statsmodels imports for statistical analysis\n",
    "from scipy.stats import pointbiserialr, chi2_contingency\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Scikit-learn imports for machine learning models, metrics, and preprocessing\n",
    "from sklearn.model_selection import (GridSearchCV, train_test_split, StratifiedKFold,\n",
    "                                     cross_val_score, StratifiedShuffleSplit, cross_validate)\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.metrics import (accuracy_score, recall_score, precision_score, f1_score, \n",
    "                             confusion_matrix, classification_report, roc_curve, auc)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# IPython for HTML display\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc69f69-5cc8-49a0-b653-401d7ab21d46",
   "metadata": {},
   "source": [
    "### CSS Styling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9b234f-f872-4205-a2a9-9590de40db15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing custom CSS for styling\n",
    "\n",
    "css = open('style.css').read()\n",
    "HTML('<style>{}</style>'.format(css))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed68394-5430-480b-b065-1de29c43dbae",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3. Data Processing & Exploration - Kaggle Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ad6ada-f619-4ad1-9904-98ced28fc770",
   "metadata": {},
   "source": [
    "### 3.1 Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150b865d-2938-43c8-a7bf-db61ae885f14",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba7255d-e550-428d-a663-45b5266eef66",
   "metadata": {},
   "source": [
    "1. Load the dataset from 'kaggle-heart.csv' into a pandas DataFrame, handling missing values.\n",
    "2. Preview the first 2 rows to ensure the data has been loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354b9448-95fe-4c39-9730-3cd3b90cad4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the kaggle-heart.csv dataset into a DataFrame called \"df_kaggle\"\n",
    "# We treat \" \", \"?\", and \"NA\" as missing values and replace them with NaN\n",
    "df_kaggle = pd.read_csv('kaggle-heart.csv', na_values=[\" \",\"?\",\"NA\"])\n",
    "\n",
    "# Display the first two rows of the dataset for inspection\n",
    "df_kaggle.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c78ac7b-b9bc-498d-af48-107e09d89523",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d2264d-bba9-4389-a0eb-7d1e8856e04c",
   "metadata": {},
   "source": [
    "1. Extract column names and data types from the dataset.\n",
    "2. Add descriptions for each column based on the dataset documentation.\n",
    "3. Calculate the min and max values for each numerical column.\n",
    "4. Combine all information into a single DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad80537f-4411-4f84-a7b9-c215741164a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Data Dictionary for the dataset:\n",
    "# We will collect the following:\n",
    "# - Field names (column names)\n",
    "# - Data types\n",
    "# - Descriptions (based on Kaggle's dataset page)\n",
    "# - Max and Min values for numerical columns\n",
    "\n",
    "# Column names and data types\n",
    "kaggle_field_list = df_kaggle.columns.tolist()  # List of column names\n",
    "kaggle_dtype_list = df_kaggle.dtypes.astype(str).tolist()  # List of column data types as strings\n",
    "\n",
    "# Description of each field based on Kaggle's dataset page\n",
    "kaggle_description_list = [\n",
    "    \"age\",\n",
    "    \"sex\",\n",
    "    \"chest pain type (4 values)\",\n",
    "    \"resting blood pressure\",\n",
    "    \"serum cholestoral in mg/dl\",\n",
    "    \"fasting blood sugar > 120 mg/dl\",\n",
    "    \"resting electrocardiographic results (values 0,1,2)\",\n",
    "    \"maximum heart rate achieved\",\n",
    "    \"exercise induced angina\",\n",
    "    \"oldpeak = ST depression induced by exercise relative to rest\",\n",
    "    \"the slope of the peak exercise ST segment\",\n",
    "    \"number of major vessels (0-3) colored by flourosopy\",\n",
    "    \"thal: 0 = normal; 1 = fixed defect; 2 = reversable defect\",\n",
    "    \"presence of heart disease. 0 = no disease and 1 = disease.\"\n",
    "]\n",
    "\n",
    "# Max and min values for each column\n",
    "kaggle_max_list = df_kaggle.max().to_list()  # List of max values for each column\n",
    "kaggle_min_list = df_kaggle.min().to_list()  # List of min values for each column\n",
    "\n",
    "# Combine all lists into one DataFrame for easier reference\n",
    "kaggle_concat_list = [\n",
    "    kaggle_field_list,\n",
    "    kaggle_dtype_list,\n",
    "    kaggle_description_list,\n",
    "    kaggle_min_list,\n",
    "    kaggle_max_list\n",
    "]\n",
    "\n",
    "# The lists need to be converted to Series before concatenating\n",
    "df_kaggle_data_dictionary = pd.DataFrame(pd.concat([pd.Series(x) for x in kaggle_concat_list], axis=1))\n",
    "\n",
    "# Set column names for the new DataFrame\n",
    "df_kaggle_data_dictionary.columns = [\"FieldName\", \"DataType\", \"Description\", \"Min\", \"Max\"]\n",
    "\n",
    "# Display the data dictionary rounded to 1 decimal point for readability\n",
    "df_kaggle_data_dictionary.round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb161528-41cb-44ff-bd96-a3603004bf12",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166afb10-3cb2-4fc4-a647-07cae4762eae",
   "metadata": {},
   "source": [
    "Generate summary statistics for the numerical columns in the dataset, rounding the results to two decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3483ddf-6750-412e-af0d-0fe18b42557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary statistics for numerical columns and round the results to two decimal places\n",
    "df_kaggle.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ca2233-e8bf-40b7-a852-f408917e9848",
   "metadata": {},
   "source": [
    "**Notes:**\n",
    "- The dataset appears to contain more rows than expected.\n",
    "- We expected 303.\n",
    "- This discrepancy may indicate data issues, such as extra rows or duplicate entries that need to be investigated and cleaned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b4dd6b-eb5c-4dc4-9dc8-7577eba475c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Count Null Values per Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcacabc-5248-44df-8cbd-5f44336411b3",
   "metadata": {},
   "source": [
    "This step counts the missing (null) values in each column to assess the completeness of the dataset and guide decisions on handling missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c3cc30-7cd3-4510-8157-d5cbb4ae32d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of missing (null) values per column in the dataset\n",
    "df_kaggle.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb92f40-799e-4388-962f-c00180139565",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Count Duplicated Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60a0b69-3d57-4178-9405-44c50cf02691",
   "metadata": {},
   "source": [
    "Calculate the number of duplicated rows in the dataset, helping identify copied data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992c7e13-ed2a-4b12-8acb-1ad9f416c910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of duplicated rows in the dataset\n",
    "df_kaggle.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7661b4f0-21d1-4142-b005-5b3627035123",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Count Unique Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7accaed8-02cf-4818-a5ae-e5be73f84401",
   "metadata": {},
   "source": [
    "Identify and count the unique rows in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929b5efc-5329-417c-88a0-6cd2a1f874f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique rows in the DataFrame (removing duplicates)\n",
    "unique_rows = np.unique(df_kaggle, axis=0)\n",
    "\n",
    "# Display the shape of the unique rows (number of unique records)\n",
    "unique_rows.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfb4077-7eae-43b9-8436-b103ef38c32d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4. Data Processing & Exploration - UCI Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22960600-c511-4d04-a54a-7e73ccc01cf3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.1 Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18978f00-2409-4dac-93e9-e7a49b2b8fe8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a78c16-2b80-44a2-857b-06f4eea79ace",
   "metadata": {},
   "source": [
    "1. Load 'processed.cleveland.data' into a DataFrame and identify na values.\n",
    "2. View the first 2 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b45f5e-dcb6-40d2-b0ee-8dd08d370ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Cleveland dataset into a DataFrame\n",
    "df_cleveland = pd.read_csv(\n",
    "    \"processed.cleveland.data\",\n",
    "    na_values=[\" \", \"?\", \"NA\"],\n",
    "    encoding=\"ISO-8859-1\",\n",
    "    header=None,\n",
    "    delimiter=\",\"\n",
    ")\n",
    "\n",
    "# View the first two rows of the Cleveland dataset\n",
    "df_cleveland.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc92cde3-904b-4a2d-821f-52cc2e512bcb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Viewing information on nulls and datatypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76409825-c58f-4261-81e9-412679b2321a",
   "metadata": {},
   "source": [
    "Display dataset structure, including non-null counts, and data types, to check for missing values and overall composition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8691554-08e1-439a-b9ec-723b0f53c86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display information about the dataset\n",
    "df_cleveland.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a44343a-49e6-4880-8862-f36889374b0a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2cd552-6bcc-471f-ad8b-5a245ab467cc",
   "metadata": {},
   "source": [
    "Create a data dictionary for the Cleveland dataset by extracting column names, data types, descriptions, and min/max values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0627bf-d69b-4041-a83a-4c3d8417f814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the dataset to df for reference\n",
    "df = df_cleveland\n",
    "\n",
    "# Creating a DataFrame showing column details: name, type, description, and min/max values\n",
    "column_details = list(zip(\n",
    "    df.columns,\n",
    "    df.dtypes.astype(str),\n",
    "    [\n",
    "        \"Age in years\",\n",
    "        \"Sex (1 = male; 0 = female)\",\n",
    "        \"Chest pain type (1: typical angina, 2: atypical angina, 3: non-anginal pain, 4: asymptomatic)\",\n",
    "        \"Resting blood pressure (mmHg on admission)\",\n",
    "        \"Serum cholesterol (mg/dL)\",\n",
    "        \"Fasting blood sugar > 120 mg/dL (1 = true, 0 = false)\",\n",
    "        \"Resting electrocardiographic results (0: normal, 1: ST-T wave abnormality, 2: probable left ventricular hypertrophy)\",\n",
    "        \"Maximum heart rate achieved\",\n",
    "        \"Exercise-induced angina (1 = yes; 0 = no)\",\n",
    "        \"ST depression induced by exercise relative to rest\",\n",
    "        \"Slope of peak exercise ST segment (1: upsloping, 2: flat, 3: downsloping)\",\n",
    "        \"Number of major vessels (0â€“3) colored by fluoroscopy\",\n",
    "        \"Thalassemia (3: normal, 6: fixed defect, 7: reversible defect)\",\n",
    "        \"Diagnosis of heart disease (0: <50% narrowing, 1: >50% narrowing)\"\n",
    "    ],\n",
    "    df.min().tolist(),\n",
    "    df.max().tolist()\n",
    "))\n",
    "\n",
    "# Creating the DataFrame\n",
    "df_cleveland_data_dictionary = pd.DataFrame(\n",
    "    column_details, \n",
    "    columns=[\"FieldName\", \"DataType\", \"Description\", \"Min\", \"Max\"]\n",
    ")\n",
    "\n",
    "# Display the DataFrame\n",
    "df_cleveland_data_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56848b5-7964-4ea7-b095-59f252b52993",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Loading the other datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdbb993-71e4-44da-ac0f-8b11b820a12c",
   "metadata": {},
   "source": [
    "Load the Hungarian, Switzerland, and Long Beach datasets into DataFrames, handling missing values, encoding, and delimiters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dce7f7-9158-4751-a840-977241883869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common parameters for reading datasets\n",
    "read_params = {\n",
    "    \"na_values\": [\" \", \"?\", \"NA\"],\n",
    "    \"encoding\": \"ISO-8859-1\",\n",
    "    \"header\": None,\n",
    "    \"delimiter\": \",\"\n",
    "}\n",
    "\n",
    "# Loading the Hungarian dataset into a DataFrame\n",
    "df_hungarian = pd.read_csv(\"processed.hungarian.data\", **read_params)\n",
    "\n",
    "# Loading the Switzerland dataset into a DataFrame\n",
    "df_switzerland = pd.read_csv(\"processed.switzerland.data\", **read_params)\n",
    "\n",
    "# Loading the Long Beach dataset into a DataFrame\n",
    "df_longbeach = pd.read_csv(\"processed.va.data\", **read_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6104108c-4e99-43aa-a445-2f621aa80a82",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Creating dictionary of location and df name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13f0a79-82b5-41ca-9494-85ca706042b9",
   "metadata": {},
   "source": [
    "Create a dictionary to store all datasets, making them easier to access by name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ecdaf7-f16f-42e4-a51e-95863389670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary to store all datasets for easier access by name\n",
    "df_all_datasets_dict = {\n",
    "    \"Cleveland\": df_cleveland,\n",
    "    \"Hungarian\": df_hungarian,\n",
    "    \"Switzerland\": df_switzerland,\n",
    "    \"Longbeach\": df_longbeach\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cf8a5d-26b7-49a7-8e97-6833e522ae6b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Getting shape of each location dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb06a7a0-73f8-4a91-8acd-e72b9514f403",
   "metadata": {},
   "source": [
    "Iterate through the datasets, retrieves the shape (rows and columns) of each, and stores the results in a summary DataFrame for easy comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f87d5a-7b3f-4da8-9bd4-976bacc1a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store the shape of each dataset\n",
    "df_shape_list = [\n",
    "    {\n",
    "        \"DataFrame\": name, \n",
    "        \"Rows\": frame.shape[0], \n",
    "        \"Columns\": frame.shape[1]\n",
    "    }\n",
    "    for name, frame in df_all_datasets_dict.items()\n",
    "]\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "df_all_shapes = pd.DataFrame(df_shape_list).set_index(\"DataFrame\")\n",
    "\n",
    "# Display the shape summary of all datasets\n",
    "df_all_shapes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6782c5f-cc5c-46bd-9079-cfdae7621055",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### New Column Names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5689a3-c849-4c59-a9bd-be87f181a977",
   "metadata": {},
   "source": [
    "Define a list of new column names that will be applied to all datasets to ensure consistency and clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb82b8c3-6904-4121-ae53-5e8f16fcc2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of new column names for the datasets\n",
    "new_column_names = [\n",
    "    \"Age\",           # Age in years\n",
    "    \"Sex\",           # 1 = male, 0 = female\n",
    "    \"ChestPain\",     # Chest pain type\n",
    "    \"RestingBP\",     # Resting blood pressure\n",
    "    \"Chol\",          # Serum cholesterol\n",
    "    \"FastingBS\",     # Fasting blood sugar > 120 mg/dl (1 = true, 0 = false)\n",
    "    \"RestingECG\",    # Resting electrocardiographic results\n",
    "    \"HeartRateMax\",  # Maximum heart rate achieved\n",
    "    \"ExeAngina\",     # Exercise induced angina (1 = yes, 0 = no)\n",
    "    \"STDep\",         # ST depression induced by exercise relative to rest\n",
    "    \"STSlope\",       # Slope of peak exercise ST segment\n",
    "    \"ColouredMV\",    # Number of major vessels (0-3) colored by fluoroscopy\n",
    "    \"Thalass\",       # Thalassemia (3 = normal, 6 = fixed defect, 7 = reversible defect)\n",
    "    \"Diagnosis\"      # Diagnosis of heart disease (0 = < 50% narrowing, 1 = > 50% narrowing)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1b5c3f-a7b3-4326-b5ee-98587519db2d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Renaming columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b1377f-ba0c-4391-8ed3-43357b855aad",
   "metadata": {},
   "source": [
    "Applies the new column names to all datasets in the df_all_datasets_dict dictionary, ensuring consistency across datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7975bd8-84fa-4ec3-9e24-888e0a3ee4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the new column names to all datasets\n",
    "for name, frame in df_all_datasets_dict.items():\n",
    "    # Assign the new column names to each DataFrame\n",
    "    frame.columns = new_column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139f11fa-898f-41ac-872a-55be1132d57f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Summarising datatypes for each column in each dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75aa07b1-23b1-42c9-94a9-8f478f732297",
   "metadata": {},
   "source": [
    "Generates a summary of the data types for each column in each dataset, concatenating the results into a single DataFrame for easier comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598a0cb5-16c5-4703-9693-4e507c989bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of DataFrames containing the data types of each dataset's columns\n",
    "df_dtype_list = []\n",
    "\n",
    "for name, frame in df_all_datasets_dict.items():\n",
    "    # Create a DataFrame of column data types for each dataset\n",
    "    df_dtype = pd.DataFrame(frame.dtypes)\n",
    "    \n",
    "    # Rename the column to the dataset name for clarity\n",
    "    df_dtype.columns = [name]\n",
    "    \n",
    "    # Append the DataFrame to the list\n",
    "    df_dtype_list.append(df_dtype)\n",
    "\n",
    "# Concatenate all DataFrames in the list into one DataFrame\n",
    "df_all_dtypes = pd.concat(df_dtype_list, axis=1)\n",
    "\n",
    "# Display the data types summary\n",
    "df_all_dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e28d8a-ff3e-4e0b-987c-fe8ab81113ac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Summarising null values in each column in each dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37991f71-dbcd-418e-9a09-3bda63e11872",
   "metadata": {},
   "source": [
    "Counts the number of null (missing) values in each column of all datasets and generates a summary DataFrame. It also displays the null count for specific columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcc8985-18c6-4ae1-bd14-0da21e453fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of DataFrames containing the null value counts for each dataset's columns\n",
    "df_null_list = []\n",
    "\n",
    "for name, frame in df_all_datasets_dict.items():\n",
    "    # Count the null values in each column of the current dataset\n",
    "    df_null = pd.DataFrame(frame.isna().sum())\n",
    "    \n",
    "    # Rename the column to the dataset name for clarity\n",
    "    df_null.columns = [name]\n",
    "    \n",
    "    # Append the DataFrame to the list\n",
    "    df_null_list.append(df_null)\n",
    "\n",
    "# Concatenate all DataFrames in the list into one DataFrame\n",
    "df_all_null = pd.DataFrame(pd.concat(df_null_list, axis=1))\n",
    "\n",
    "# Save the null values summary to a CSV file\n",
    "df_all_null.to_csv(\"UCI_location_nulls.csv\", index=True)\n",
    "\n",
    "# Display the null values count for specific columns of interest\n",
    "df_all_null.loc[[\"RestingBP\", \"Chol\", \"FastingBS\", \"RestingECG\", \"HeartRateMax\", \n",
    "                 \"ExeAngina\", \"STDep\", \"STSlope\", \"ColouredMV\", \"Thalass\"]].T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153f6443-a96c-48f6-a190-f2ca99842c16",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Adding Location column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1b4b2f-7362-4c72-9626-146171632395",
   "metadata": {},
   "source": [
    "Add a new column, \"Location,\" to each dataset, which stores the name of the dataset as a string to track its source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f439e76b-442a-4412-a2fa-f811c06e5aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a \"Location\" column to each dataset to identify the dataset source\n",
    "for name, frame in df_all_datasets_dict.items():\n",
    "    # Assign the dataset name to the new \"Location\" column\n",
    "    frame[\"Location\"] = name\n",
    "    \n",
    "    # Ensure that the \"Location\" column is stored as a string\n",
    "    frame[\"Location\"] = frame[\"Location\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fcb9c1-8e3b-4333-b47d-b32a34a6eeea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Combining datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77ccc15-6d07-4538-a6f5-17eaee0f395a",
   "metadata": {},
   "source": [
    "Concatenate all datasets into a single DataFrame and displays the first three rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7259e55e-88ce-45e7-8654-b0a3470011ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all datasets into one combined DataFrame\n",
    "df_combined = pd.concat(df_all_datasets_dict.values(), ignore_index=True)\n",
    "\n",
    "# Display the first three rows of the combined dataset\n",
    "df_combined.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2e473d-de76-470d-9fb1-fdd9e4e0c201",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Removing rows with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f092d18-6a4d-4b05-bb4a-ed524690b17c",
   "metadata": {},
   "source": [
    "Count the number of rows in the combined dataset that contain any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efbf172-5726-464c-bf60-51cd1616f795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of rows in the combined dataset with any missing values\n",
    "missing_rows_count = len(df_combined[df_combined.isna().any(axis=1)])\n",
    "missing_rows_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b335cce-f15e-470f-a29a-0576d84955cc",
   "metadata": {},
   "source": [
    "Drop rows with any missing values from the combined dataset and displays the shape of the cleaned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ece1097-4472-466e-9068-d16dbf8f6ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with any missing values from the combined dataset\n",
    "df_combined = df_combined.dropna()\n",
    "\n",
    "# Display the shape of the cleaned dataset\n",
    "df_combined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b940602a-9ea7-489a-8121-b5a3cadd2d24",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Counting remaining rows from each dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9b52a5-a027-4a50-a785-a4c3b4792948",
   "metadata": {},
   "source": [
    "Count the number of rows for each dataset in the combined dataset and displays the results in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec35d03-4140-4f60-950f-df1a6f6d705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of rows for each dataset in the combined dataset\n",
    "location_count_list = []\n",
    "\n",
    "for name, frame in df_all_datasets_dict.items():\n",
    "    # Get the count of rows for each location (dataset)\n",
    "    location_count = (name, df_combined[df_combined[\"Location\"] == name].shape[0])\n",
    "    location_count_list.append(location_count)\n",
    "\n",
    "# Create a DataFrame to display the count of rows per dataset location\n",
    "df_location_count = pd.DataFrame(location_count_list, columns=[\"DataFrame\", \"NoNulls\"]).style.hide(axis=\"index\")\n",
    "\n",
    "# Display the count of rows for each dataset\n",
    "df_location_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09f7304-f620-4270-80d2-aff56aec9264",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Creating dictionary of datatypes for columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c6da6c-d6be-4977-9966-9b91e57fe66e",
   "metadata": {},
   "source": [
    "Convert specific columns in the df_combined DataFrame to their appropriate data types and display the resulting data types of all columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce34a8e7-517f-432e-a4aa-366aa32be759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns to appropriate data types\n",
    "df_combined = df_combined.astype({\n",
    "    \"Age\": \"int64\",\n",
    "    \"Sex\": \"category\",\n",
    "    \"ChestPain\": \"category\",\n",
    "    \"RestingBP\": \"int64\",\n",
    "    \"Chol\": \"int64\",\n",
    "    \"FastingBS\": \"category\",\n",
    "    \"RestingECG\": \"category\",\n",
    "    \"HeartRateMax\": \"int64\",\n",
    "    \"ExeAngina\": \"category\",\n",
    "    \"STDep\": \"float64\",\n",
    "    \"STSlope\": \"category\",\n",
    "    \"ColouredMV\": \"int64\",\n",
    "    \"Thalass\": \"category\",\n",
    "    \"Diagnosis\": \"category\"\n",
    "})\n",
    "\n",
    "# Confirm the data types of each column in a structured format\n",
    "df_combined_dtypes = pd.DataFrame(df_combined.dtypes, columns=[\"Dtype\"])\n",
    "df_combined_dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c558bda-7e15-4a53-b624-1515c7903184",
   "metadata": {},
   "source": [
    "Looking at first five rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022fef1b-e90a-4a2d-b864-022ea043ea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec9b47b-4bbc-45d1-beb3-f82b6cbbdafc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Adding SexMF column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c7a1c4-d546-4e8b-9b21-41730453991e",
   "metadata": {},
   "source": [
    "Add a new column SexMF to the df_combined DataFrame, replacing 0 and 1 in the Sex column with F and M."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4e5e5f-3ceb-47a2-9328-8d369a6f63bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'Sex' column is categorical and rename categories to 'F' and 'M'\n",
    "if df_combined[\"Sex\"].dtype.name == \"category\":\n",
    "    df_combined[\"SexMF\"] = df_combined[\"Sex\"].cat.rename_categories({0: \"F\", 1: \"M\"})\n",
    "\n",
    "# Confirm the first few rows of the newly created 'SexMF' column\n",
    "df_combined[[\"Sex\", \"SexMF\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e3a4cb-cfdf-4968-b486-d3b9e6968765",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Changing categorical values in cat columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b461ef18-c204-440c-9819-c91ae4cdd3e3",
   "metadata": {},
   "source": [
    "Rename groups in categorical columns based on a predefined dictionary, modifying the category values in the df_combined DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca7a367-c165-44bb-8f46-e0bc00860705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for category renaming\n",
    "dict_column_changes = {\n",
    "    \"Sex\": {1.0: 1, 0.0: 0},\n",
    "    \"ChestPain\": {1.0: 1, 2.0: 2, 3.0: 3, 4.0: 4},\n",
    "    \"FastingBS\": {0.0: 0, 1.0: 1},\n",
    "    \"RestingECG\": {0.0: 0, 1.0: 1, 2.0: 2},\n",
    "    \"ExeAngina\": {1.0: 1, 0.0: 0},\n",
    "    \"STSlope\": {1.0: 1, 2.0: 2, 3.0: 3},\n",
    "    \"Thalass\": {3.0: 3, 6.0: 6, 7.0: 7}\n",
    "}\n",
    "\n",
    "# Rename the categories safely\n",
    "for col, change in dict_column_changes.items():\n",
    "    if df_combined[col].dtype.name == \"category\":\n",
    "        df_combined[col] = df_combined[col].cat.rename_categories(change)\n",
    "\n",
    "# Display a sample to confirm changes\n",
    "df_combined[dict_column_changes.keys()].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d19a62-4d6d-457b-9115-1f16de3ad79c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Checking if categorical data is ordered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b39eda7-24c1-44ff-96c1-1d7ba1c28c39",
   "metadata": {},
   "source": [
    "Check each column in df_combined to identify if categorical data is ordered and display the category labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6d3b22-c84b-4f60-96bd-f5a162140247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect each column for data type and order status\n",
    "for col in df_combined:\n",
    "    if df_combined[col].dtype == \"category\":\n",
    "        print(f\"Column: {col}\\nCategories: {df_combined[col].cat.categories.tolist()}\\nOrdered: {df_combined[col].cat.ordered}\\n\")\n",
    "    else:\n",
    "        print(f\"Column: {col}\\nData Type: {df_combined[col].dtype}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e96da39-ca73-499b-a2c7-65e09be19ba1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Making \"Diagnosis\" ordered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29df8fc9-3422-4a45-b01b-ecec794d2fca",
   "metadata": {},
   "source": [
    "Convert the Diagnosis column to an ordered categorical variable with specified categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7762f7bb-3365-4c2e-b647-bc76d29e4bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Diagnosis' column to an ordered categorical variable with defined levels\n",
    "df_combined[\"Diagnosis\"] = pd.Categorical(\n",
    "    df_combined[\"Diagnosis\"], \n",
    "    categories=[0, 1, 2, 3, 4], \n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Confirm the updated categorical properties\n",
    "print(f\"Categories: {df_combined['Diagnosis'].cat.categories.tolist()}\")\n",
    "print(f\"Ordered: {df_combined['Diagnosis'].cat.ordered}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43edee56-ac5d-43d0-8c9c-f351bc51884e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Making \"DiagnosisYN\" column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1187b9-1bcd-45b3-885a-d2476f6cbdcf",
   "metadata": {},
   "source": [
    "Create a new column DiagnosisYN to classify Diagnosis into binary categories (1: heart disease, 0: no heart disease) and convert it to a categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c183b209-9b36-4122-9384-33b52017b7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new binary column 'DiagnosisYN' based on 'Diagnosis'\n",
    "# 1 for heart disease (1-4), 0 for no heart disease (0)\n",
    "df_combined[\"DiagnosisYN\"] = np.where(df_combined[\"Diagnosis\"].isin([1, 2, 3, 4]), 1, 0)\n",
    "\n",
    "# Convert 'DiagnosisYN' to a categorical variable with defined categories\n",
    "df_combined[\"DiagnosisYN\"] = pd.Categorical(df_combined[\"DiagnosisYN\"], categories=[0, 1], ordered=False)\n",
    "\n",
    "# Verify the new column's categorical properties\n",
    "print(f\"Categories: {df_combined['DiagnosisYN'].cat.categories.tolist()}\")\n",
    "print(f\"Ordered: {df_combined['DiagnosisYN'].cat.ordered}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65c8a05-e019-4e51-afcd-4fea931c6c6f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Check Dtypes and summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7a072e-7d65-4cf9-8e92-e50ab6ca6e5f",
   "metadata": {},
   "source": [
    "Display the data types of all columns in the df_combined DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86c6cd5-3990-4755-a306-6301c2dd8239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the data types of all columns in the DataFrame\n",
    "df_combined.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91e922f-cebf-4509-945d-903b7e1a372a",
   "metadata": {},
   "source": [
    "Generate and round summary statistics for all numeric columns in the df_combined DataFrame to two decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6b387a-3c3d-4a72-9d72-6d3316c99a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary statistics for numeric columns and round to 2 decimal places\n",
    "df_combined.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eac734-d3e3-4d08-8ac5-834dea0bb4ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Summary statistics for each Diagnosis type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7827789-9cd4-41e7-a8af-e53e3920928b",
   "metadata": {},
   "source": [
    "Generate separate summary statistics for rows in df_combined where DiagnosisYN is 0 and 1, rounding the results to two decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6513c47c-95fe-4695-a527-e2c4d7d7fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary for DiagnosisYN == 0\n",
    "summary_no_disease = df_combined[df_combined[\"DiagnosisYN\"] == 0].describe().round(2)\n",
    "\n",
    "# Summary for DiagnosisYN == 1\n",
    "summary_disease = df_combined[df_combined[\"DiagnosisYN\"] == 1].describe().round(2)\n",
    "\n",
    "# Optionally display summaries\n",
    "display(summary_no_disease, summary_disease)\n",
    "\n",
    "# Alternative: Group by DiagnosisYN for concise summaries\n",
    "grouped_summary = df_combined.groupby(\"DiagnosisYN\", observed=False).describe().round(2)\n",
    "grouped_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711adfad-c52c-464e-9901-c50d2a498262",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.2 Data Exploration - Visualisations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3445f3be-4dcd-4f6d-bb45-356334ca03f1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Making lists of categorical data and numerical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3623c70-151b-4a7a-9ebb-3ea7d559700f",
   "metadata": {},
   "source": [
    "Create separate lists for categorical and numerical columns to organize the dataset for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da77cf2-3b6c-4dda-9c75-02dc37297119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists for categorical and numerical columns for easy access\n",
    "columns_for_categorical = [\n",
    "    \"SexMF\",    # Gender (Male/Female)\n",
    "    \"ChestPain\", # Type of chest pain\n",
    "    \"FastingBS\", # Fasting blood sugar\n",
    "    \"RestingECG\", # Resting electrocardiographic results\n",
    "    \"ExeAngina\",  # Exercise induced angina\n",
    "    \"STSlope\",    # Slope of the peak exercise ST segment\n",
    "    \"Thalass\",    # Thalassemia\n",
    "    \"Diagnosis\",  # Diagnosis (original classes)\n",
    "    \"DiagnosisYN\" # Diagnosis (binary: 1 for heart disease, 0 for no heart disease)\n",
    "]\n",
    "\n",
    "columns_for_numerical = [\n",
    "    \"Age\",          # Age of the patient\n",
    "    \"RestingBP\",    # Resting blood pressure\n",
    "    \"Chol\",         # Cholesterol levels\n",
    "    \"HeartRateMax\", # Maximum heart rate achieved\n",
    "    \"STDep\",        # Depression of the ST segment\n",
    "    \"ColouredMV\"    # Number of colored major vessels\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1100ffb5-d1c2-4b15-8150-dcd8deca2e58",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Bar Chart - Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38ff225-03d6-43f8-9e8b-b4d6dd4da5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a count plot for 'SexMF' grouped by 'DiagnosisYN'\n",
    "plt.figure(figsize=(4, 5))\n",
    "\n",
    "sns.countplot(\n",
    "    x=\"SexMF\", \n",
    "    order=[\"M\", \"F\"], \n",
    "    palette=\"Set3\", \n",
    "    hue=\"DiagnosisYN\", \n",
    "    data=df_combined\n",
    ")\n",
    "\n",
    "# Adding title, labels, and styling\n",
    "plt.title(\"Sex by Heart Disease Diagnosis\", fontsize=10, fontweight='bold')\n",
    "plt.xlabel('Sex', fontsize=12)\n",
    "plt.xticks(\n",
    "    ticks=[0, 1],\n",
    "    labels=[\"M\", \"F\"],\n",
    "    fontsize=8\n",
    ")\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.legend(\n",
    "    title='Diagnosis', \n",
    "    labels=['No', 'Yes'], \n",
    "    loc='upper right',\n",
    "    fontsize=10\n",
    ")\n",
    "\n",
    "# Adjusting layout to avoid clipping\n",
    "plt.subplots_adjust(top=0.95)\n",
    "plt.subplots_adjust(left=0.15)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f77888f-8232-445d-b0f8-e6957a48aa95",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Bar Chart - ChestPain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f9005e-de41-4721-aa6a-596c98368efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a count plot for the 'DiagnosisYN' column, grouped by 'ChestPain'\n",
    "plt.figure(figsize=(4,5))\n",
    "\n",
    "sns.countplot(\n",
    "    x=\"DiagnosisYN\", \n",
    "    order=[\"0\",\"1\"], \n",
    "    palette=\"Set3\", \n",
    "    hue=\"ChestPain\", \n",
    "    data=df_combined\n",
    ")\n",
    "\n",
    "# Adding title, labels and styling\n",
    "plt.title(\"Heart Disease Diagnosis by Chest Pain Type\", fontsize=10, fontweight='bold')\n",
    "plt.xlabel('Diagnosis', fontsize=12)\n",
    "plt.xticks(\n",
    "    ticks = [0, 1],\n",
    "    labels = [\"N\",\"Y\"],\n",
    "    fontsize = 8\n",
    ")\n",
    "\n",
    "# Customize legend to show chest pain types\n",
    "plt.legend(\n",
    "    title='Pain Type', \n",
    "    labels=[\"Typical Angina\", \"Atypical Angina\", \"Non-Anginal Pain\", \"Asymptomatic\"], \n",
    "    loc='upper left',\n",
    "    fontsize=8\n",
    ")\n",
    "\n",
    "# Adjusting layout to avoid clipping\n",
    "plt.subplots_adjust(top=0.95)\n",
    "plt.subplots_adjust(left=0.15)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbc0afe-b891-4a1e-b15b-a99e46b321de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Bar Chart - FastingBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9602750e-8b8f-4123-a7b5-88c6c64f09a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a count plot for 'FastingBS', grouped by 'DiagnosisYN'\n",
    "plt.figure(figsize=(5, 6))\n",
    "\n",
    "sns.countplot(\n",
    "    x=\"FastingBS\", \n",
    "    order=[\"0\", \"1\"],  # FastingBS: 0 = False, 1 = True\n",
    "    palette=\"Set3\", \n",
    "    hue=\"DiagnosisYN\",  # Hue by heart disease diagnosis\n",
    "    data=df_combined\n",
    ")\n",
    "\n",
    "# Add title, labels, and styling\n",
    "plt.title(\"Fasting Blood Sugar by Heart Disease Diagnosis\", fontsize=10, fontweight='bold')\n",
    "plt.xlabel('Fasting blood sugar ( > 120 mg/dL)', fontsize=12)\n",
    "plt.xticks(\n",
    "    ticks=[0, 1],\n",
    "    labels=[\"False\", \"True\"],  # Labels for FastingBS: False = 0, True = 1\n",
    "    fontsize=10\n",
    ")\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "\n",
    "# Customize legend to show diagnosis categories\n",
    "plt.legend(\n",
    "    title='Diagnosis', \n",
    "    labels=['No', 'Yes'],  # Legend for diagnosis: No = 0, Yes = 1\n",
    "    loc='upper right',\n",
    "    fontsize=10\n",
    ")\n",
    "\n",
    "# Adjust layout\n",
    "plt.subplots_adjust(top=0.8)\n",
    "plt.subplots_adjust(left=0.15)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c893345-33ea-4754-8678-4a6f6398df34",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Bar Chart - RestingECG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c493e79a-9d0f-41b9-aa98-f99370b672fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a count plot for 'RestingECG', grouped by 'DiagnosisYN'\n",
    "plt.figure(figsize=(5, 6))\n",
    "\n",
    "sns.countplot(\n",
    "    x=\"RestingECG\", \n",
    "    order=[\"0\", \"1\", \"2\"],  # RestingECG: 0 = Normal, 1 = ST-T Abnormality, 2 = Hypertrophy\n",
    "    palette=\"Set3\", \n",
    "    hue=\"DiagnosisYN\",  # Hue by heart disease diagnosis\n",
    "    data=df_combined\n",
    ")\n",
    "\n",
    "# Add title, labels, and styling\n",
    "plt.title(\"Resting ECG Results by Heart Disease Diagnosis\", fontsize=10, fontweight='bold')\n",
    "plt.xlabel('Resting ECG Results', fontsize=12)\n",
    "plt.xticks(\n",
    "    ticks=[0, 1, 2],  # x-axis ticks for ECG results\n",
    "    labels=[\"Normal\", \"ST-T Abnormality\", \"Hypertrophy\"],  # RestingECG categories\n",
    "    fontsize=10\n",
    ")\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "\n",
    "# Customize legend to show diagnosis categories\n",
    "plt.legend(\n",
    "    title='Diagnosis', \n",
    "    labels=['No', 'Yes'],  # Legend for diagnosis: No = 0, Yes = 1\n",
    "    loc='upper center',\n",
    "    fontsize=10\n",
    ")\n",
    "\n",
    "# Adjust layout\n",
    "plt.subplots_adjust(top=0.8)\n",
    "plt.subplots_adjust(left=0.15)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3a591a-8e0d-4c8d-a513-bfbb701c5aa6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Bar Chart - ExeAngina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47bb003-a9d0-43a8-8081-e96a502b5df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a count plot for 'ExeAngina', grouped by 'DiagnosisYN'\n",
    "plt.figure(figsize=(5, 6))\n",
    "\n",
    "sns.countplot(\n",
    "    x=\"ExeAngina\", \n",
    "    order=[\"0\", \"1\"],  # ExeAngina: 0 = No, 1 = Yes\n",
    "    palette=\"Set3\", \n",
    "    hue=\"DiagnosisYN\",  # Hue by heart disease diagnosis\n",
    "    data=df_combined\n",
    ")\n",
    "\n",
    "# Add title, labels, and styling\n",
    "plt.title(\"Exercise Induced Angina by Heart Disease Diagnosis\", fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Exercise Induced Angina', fontsize=12)\n",
    "plt.xticks(\n",
    "    ticks=[0, 1],  # x-axis ticks for angina types\n",
    "    labels=['No', 'Yes'],  # Labels for ExeAngina categories\n",
    "    fontsize=12\n",
    ")\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "\n",
    "# Customize legend to show diagnosis categories\n",
    "plt.legend(\n",
    "    title='Diagnosis', \n",
    "    labels=['No', 'Yes'],  # Legend for diagnosis: No = 0, Yes = 1\n",
    "    loc='upper right',\n",
    "    fontsize=10\n",
    ")\n",
    "\n",
    "# Adjust layout to avoid clipping\n",
    "plt.subplots_adjust(top=0.8)\n",
    "plt.subplots_adjust(left=0.15)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bf9323-3ec5-4df8-86ea-60cbb13c1ed8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Bar Chart - STSlope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72e531b-3dac-403a-abd6-bde221810a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a count plot for 'STSlope', grouped by 'DiagnosisYN'\n",
    "plt.figure(figsize=(5, 6))\n",
    "\n",
    "sns.countplot(\n",
    "    x=\"STSlope\", \n",
    "    order=[\"1\", \"2\", \"3\"],  # Order for ST Slope: 1 = Upsloping, 2 = Flat, 3 = Downsloping\n",
    "    palette=\"Set3\", \n",
    "    hue=\"DiagnosisYN\",  # Hue by heart disease diagnosis\n",
    "    data=df_combined\n",
    ")\n",
    "\n",
    "# Add title, labels, and styling\n",
    "plt.title(\"ST Slope by Heart Disease Diagnosis\", fontsize=12, fontweight='bold')\n",
    "plt.xlabel('ST Slope', fontsize=12)\n",
    "plt.xticks(\n",
    "    ticks=[0, 1, 2],  # x-axis ticks for slope types\n",
    "    labels=[\"Upsloping\", \"Flat\", \"Downsloping\"],  # Labels for Slope categories\n",
    "    fontsize=10\n",
    ")\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "\n",
    "# Customize legend to show diagnosis categories\n",
    "plt.legend(\n",
    "    title='Diagnosis', \n",
    "    labels=['No', 'Yes'],  # Legend for diagnosis: No = 0, Yes = 1\n",
    "    loc='upper right',\n",
    "    fontsize=10\n",
    ")\n",
    "\n",
    "# Adjust layout to avoid clipping\n",
    "plt.subplots_adjust(top=0.8)\n",
    "plt.subplots_adjust(left=0.15)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf33d19d-8cf3-44be-9ac2-b8cdc7e8b76f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Bar Chart - Thalass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94b55ef-e1b0-4205-842f-ab1f8f8bdde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a count plot for 'Thalass', grouped by 'DiagnosisYN'\n",
    "plt.figure(figsize=(5, 6))\n",
    "\n",
    "sns.countplot(\n",
    "    x=\"Thalass\", \n",
    "    order=[\"3\", \"6\", \"7\"],  # Order for Thalassemia status: 3 = Normal, 6 = Fixed Defect, 7 = Reversible Defect\n",
    "    palette=\"Set3\", \n",
    "    hue=\"DiagnosisYN\",  # Hue by heart disease diagnosis\n",
    "    data=df_combined\n",
    ")\n",
    "\n",
    "# Add title, labels, and styling\n",
    "plt.title(\"Thalassemia Status by Heart Disease Diagnosis\", fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Thalassemia Status', fontsize=12)\n",
    "plt.xticks(\n",
    "    ticks=[0, 1, 2],  # x-axis ticks for Thalassemia categories\n",
    "    labels=[\"Normal\", \"Fixed Defect\", \"Reversible Defect\"],  # Labels for Thalassemia categories\n",
    "    fontsize=10\n",
    ")\n",
    "\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "\n",
    "# Customize legend to show diagnosis categories\n",
    "plt.legend(\n",
    "    title='Diagnosis', \n",
    "    labels=['No', 'Yes'],  # Legend for diagnosis: No = 0, Yes = 1\n",
    "    loc='upper right',\n",
    "    fontsize=10\n",
    ")\n",
    "\n",
    "# Adjust layout to avoid clipping\n",
    "plt.subplots_adjust(top=0.95)\n",
    "plt.subplots_adjust(left=0.15)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fb96df-187f-4633-9c93-45e05e260bc3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Bar Chart - ColouredMV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26a9f51-9f47-43d6-9b59-f752996c59fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a count plot for 'ColouredMV', grouped by 'DiagnosisYN'\n",
    "plt.figure(figsize=(5,6))\n",
    "\n",
    "sns.countplot(\n",
    "    x=\"ColouredMV\", \n",
    "    order=[\"0\", \"1\", \"2\", \"3\"],  # Order for coloured major vessels: 0 = No vessels, 1-3 = Different numbers of vessels\n",
    "    palette=\"Set3\", \n",
    "    hue=\"DiagnosisYN\",  # Hue by heart disease diagnosis\n",
    "    data=df_combined\n",
    ")\n",
    "\n",
    "# Add title, labels, and styling\n",
    "plt.title(\"Fluoroscopy Results by Heart Disease Diagnosis\", fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Coloured Major Vessels', fontsize=12)\n",
    "plt.xticks(\n",
    "    ticks=[0, 1, 2, 3],  # x-axis ticks for coloured vessels\n",
    "    labels=[\"0\", \"1\", \"2\", \"3\"],  # Labels for number of vessels\n",
    "    fontsize=10\n",
    ")\n",
    "\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "\n",
    "# Customize legend to show diagnosis categories\n",
    "plt.legend(\n",
    "    title='Diagnosis', \n",
    "    labels=['No', 'Yes'],  # Legend for diagnosis: No = 0, Yes = 1\n",
    "    loc='upper right',\n",
    "    fontsize=10\n",
    ")\n",
    "\n",
    "# Adjust layout to avoid clipping\n",
    "plt.subplots_adjust(top=0.8)\n",
    "plt.subplots_adjust(left=0.15)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff667dc5-a616-4866-9b5c-0761ffcbb4db",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Histogram - Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c94796-701c-43dd-9a97-bc4d567a61d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "att = \"Age\"\n",
    "att_name = \"Age (Years)\"\n",
    "title = \"Overlayed Histograms of Age\\n for Heart Disease vs. No Heart Disease\"\n",
    "\n",
    "plt.figure(figsize=(5,6))\n",
    "\n",
    "# Create a histogram of 'Age' with KDE, grouped by heart disease diagnosis\n",
    "sns.histplot(\n",
    "    data=df_combined,\n",
    "    x=att,\n",
    "    hue=\"DiagnosisYN\",  # Group by heart disease diagnosis\n",
    "    hue_order=[0,1],  # Order for the hue: No heart disease first\n",
    "    kde=True,  # Kernel Density Estimate for smooth distribution curve\n",
    "    bins=20,  # Increase the number of bins for more granularity\n",
    "    palette=\"Set2\",  # Color palette for the groups\n",
    "    multiple=\"dodge\",  # Separate the histograms for each group\n",
    "    alpha=0.6  # Transparency for better overlay visibility\n",
    ")\n",
    "\n",
    "# Title, labels, and styling\n",
    "plt.title(title, fontsize=12, fontweight='bold')\n",
    "plt.xlabel(att_name, fontsize=12)\n",
    "plt.ylabel(\"Frequency\", fontsize=12)\n",
    "\n",
    "# Customize the legend\n",
    "plt.legend(\n",
    "    title='Diagnosis', \n",
    "    labels=[\"Yes\", \"No\"],  # Labels for the diagnosis groups\n",
    "    loc='upper right',\n",
    "    fontsize=10\n",
    ")\n",
    "\n",
    "# Adjust layout\n",
    "plt.subplots_adjust(top=0.92)\n",
    "plt.subplots_adjust(left=0.15)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8d6224-3aa6-4aa4-9221-a8cb7b46cd31",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Box Plot - Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c68facd-815b-47ea-8e96-af7b404dcf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "att = \"Age\"\n",
    "att_name = \"Age (Years)\"\n",
    "title = \"Box Plots of Age\\n for Heart Disease vs. No Heart Disease\"\n",
    "\n",
    "plt.figure(figsize=(4,5))\n",
    "\n",
    "# Create a box plot for 'Age', grouped by heart disease diagnosis\n",
    "sns.boxplot(\n",
    "    data=df_combined,\n",
    "    x=\"DiagnosisYN\",  # Group by heart disease diagnosis\n",
    "    y=att,  # The variable 'Age'\n",
    "    hue=\"DiagnosisYN\",  # Coloring by diagnosis\n",
    "    palette=\"Set2\",  # Color palette for the groups\n",
    "    showmeans=True,  # Show the mean values on the plot\n",
    "    width=0.5  # Adjust the width for better spacing\n",
    ")\n",
    "\n",
    "# Title, labels, and styling\n",
    "plt.title(title, fontsize=12, fontweight='bold')\n",
    "plt.xlabel(\"Diagnosis\", fontsize=12)\n",
    "plt.ylabel(att_name, fontsize=12)\n",
    "\n",
    "# Customize the x-ticks to show 'No' and 'Yes' instead of 0 and 1\n",
    "plt.xticks(\n",
    "    ticks=[0, 1], \n",
    "    labels=['No', 'Yes'],  # Replace '0' with 'No' and '1' with 'Yes'\n",
    "    fontsize=12\n",
    ")\n",
    "\n",
    "# Remove the legend\n",
    "plt.legend([], [], frameon=False)\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.subplots_adjust(left=0.2)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d6d33d-9b4a-49ba-9ee4-5e2042aded61",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Histogram - RestingBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15aad77-726f-4cdb-9405-d8bc292d3ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "att = \"RestingBP\"\n",
    "att_name = \"Resting Blood Pressure (mm/Hg on admission)\"\n",
    "title = \"Overlayed Histograms of Resting Blood Pressure\\n for Heart Disease vs. No Heart Disease\"\n",
    "\n",
    "plt.figure(figsize=(5,6))\n",
    "\n",
    "# Create a histogram of 'RestingBP' with KDE, grouped by heart disease diagnosis\n",
    "sns.histplot(\n",
    "    data=df_combined,\n",
    "    x=att,\n",
    "    hue=\"DiagnosisYN\",  # Group by heart disease diagnosis\n",
    "    hue_order=[0,1],  # Order for the hue: No heart disease first\n",
    "    kde=True,  # Kernel Density Estimate for smooth distribution curve\n",
    "    bins=20,  # Increase the number of bins for more granularity\n",
    "    palette=\"Set2\",  # Color palette for the groups\n",
    "    multiple=\"dodge\",  # Separate the histograms for each group\n",
    "    alpha=0.6  # Transparency for better overlay visibility\n",
    ")\n",
    "\n",
    "# Title, labels, and styling\n",
    "plt.title(title, fontsize=12, fontweight='bold')\n",
    "plt.xlabel(att_name, fontsize=12)\n",
    "plt.ylabel(\"Frequency\", fontsize=12)\n",
    "\n",
    "# Customize the legend\n",
    "plt.legend(\n",
    "    title='Diagnosis', \n",
    "    labels=[\"Yes\", \"No\"],  # Labels for the diagnosis groups\n",
    "    loc='upper right',\n",
    "    fontsize=10\n",
    ")\n",
    "\n",
    "# Adjust layout\n",
    "plt.subplots_adjust(top=0.8)\n",
    "plt.subplots_adjust(left=0.15)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c58dca-4cdb-4e05-92be-28794e2a4d72",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Box Plot - RestingBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179e302c-690c-46bf-929e-7f97ad6dc479",
   "metadata": {},
   "outputs": [],
   "source": [
    "att = \"RestingBP\"\n",
    "att_name = \"Resting Blood Pressure (mm/Hg on admission)\"\n",
    "title = \"Box Plots of Resting Blood Pressure\\n for Heart Disease vs. No Heart Disease\"\n",
    "\n",
    "plt.figure(figsize=(4,5))\n",
    "\n",
    "# Create a box plot for 'RestingBP', grouped by 'DiagnosisYN'\n",
    "sns.boxplot(\n",
    "    data=df_combined,\n",
    "    x=\"DiagnosisYN\",  # Group by heart disease diagnosis\n",
    "    y=att,  # Plot RestingBP on the y-axis\n",
    "    hue=\"DiagnosisYN\",  # Add color based on diagnosis\n",
    "    palette=\"Set2\",  # Color palette for the groups\n",
    "    showmeans=True  # Show mean values on the box plot\n",
    ")\n",
    "\n",
    "# Title, labels, and styling\n",
    "plt.title(title, fontsize=12, fontweight='bold')\n",
    "plt.xlabel(\"Diagnosis\", fontsize=12)\n",
    "plt.ylabel(att_name, fontsize=10)\n",
    "\n",
    "# Customize x-ticks\n",
    "plt.xticks(\n",
    "    ticks=[0, 1], \n",
    "    labels=['No', 'Yes'],  # Replace 0 with 'No' and 1 with 'Yes'\n",
    "    fontsize=12\n",
    ")\n",
    "\n",
    "# Remove the legend\n",
    "plt.legend([],[],frameon=False)\n",
    "\n",
    "# Adjust layout\n",
    "plt.subplots_adjust(top=0.8)\n",
    "plt.subplots_adjust(left=0.2)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b1e954-1634-4333-aac5-9c0c7b20dae6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Histogram - Chol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f0dcf1-a23d-4136-a44f-ab53ee12f9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "att = \"Chol\"\n",
    "att_name = \"Serum Cholestorol (mg/dL)\"\n",
    "title = \"Overlayed Histograms of Serum Cholersterol\\n for Heart Disease vs. No Heart Disease\"\n",
    "\n",
    "plt.figure(figsize=(4,5))\n",
    "\n",
    "# Create a histogram with KDE for 'Chol', grouped by 'DiagnosisYN'\n",
    "sns.histplot(\n",
    "    data=df_combined,\n",
    "    x=att,  # Plot Serum Cholesterol on the x-axis\n",
    "    hue=\"DiagnosisYN\",  # Group by heart disease diagnosis\n",
    "    hue_order=[0, 1],  # '0' for No, '1' for Yes\n",
    "    kde=True,  # Add KDE for smoother distribution visualization\n",
    "    bins=15,  # Number of bins\n",
    "    palette=\"Set2\",  # Color palette for the groups\n",
    "    multiple=\"dodge\",  # Separate histograms for different hues\n",
    "    alpha=0.5  # Transparency to overlay the histograms\n",
    ")\n",
    "\n",
    "# Add title, labels, and styling\n",
    "plt.title(title, fontsize=12, fontweight='bold')\n",
    "plt.xlabel(att_name, fontsize=12)\n",
    "plt.ylabel(\"Frequency\", fontsize=12)\n",
    "\n",
    "# Customize the legend\n",
    "plt.legend(\n",
    "    title='Diagnosis', \n",
    "    labels=[\"Yes\", \"No\"], \n",
    "    loc='upper right', \n",
    "    fontsize=10\n",
    ")\n",
    "\n",
    "# Adjust layout to avoid clipping\n",
    "plt.subplots_adjust(top=0.92)\n",
    "plt.subplots_adjust(left=0.15)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55df046d-91c1-4577-bafd-196a73524253",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Box Plot - Chol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c635a3-41de-46c2-99df-e5bca32fc263",
   "metadata": {},
   "outputs": [],
   "source": [
    "att = \"Chol\"\n",
    "att_name = \"Serum Cholestorol (mg/dL)\"\n",
    "title = \"Box Plots of Serum Cholestorol\\n for Heart Disease vs. No Heart Disease\"\n",
    "\n",
    "plt.figure(figsize=(4,5))\n",
    "\n",
    "# Create a boxplot for 'Chol', grouped by 'DiagnosisYN'\n",
    "sns.boxplot(\n",
    "    data=df_combined,\n",
    "    x=\"DiagnosisYN\",  # Group by diagnosis (Heart Disease vs. No Heart Disease)\n",
    "    y=att,  # Plot Serum Cholesterol on the y-axis\n",
    "    hue=\"DiagnosisYN\",  # Color the boxes by diagnosis\n",
    "    palette=\"Set2\",  # Color palette for the groups\n",
    "    showmeans=True  # Show the mean value in the boxplot\n",
    ")\n",
    "\n",
    "# Add title and axis labels\n",
    "plt.title(title, fontsize=12, fontweight='bold')\n",
    "plt.xlabel(\"Diagnosis\", fontsize=12)\n",
    "plt.ylabel(att_name, fontsize=12)\n",
    "\n",
    "# Customize x-ticks to display \"No\" and \"Yes\" for diagnosis\n",
    "plt.xticks(\n",
    "    ticks=[0, 1], \n",
    "    labels=['No', 'Yes'],  # Replace '0' with 'No' and '1' with 'Yes'\n",
    "    fontsize=12\n",
    ")\n",
    "\n",
    "# Remove the legend as it is redundant with the labels on the x-axis\n",
    "plt.legend([],[],frameon=False)\n",
    "\n",
    "# Adjust layout to avoid clipping\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.subplots_adjust(left=0.25)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7d1b46-6223-4e80-b277-e38400b6fd38",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Histogram - HeartRateMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c19de36-4b30-4a9b-869b-f32859fcea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "att = \"HeartRateMax\"\n",
    "att_name = \"Maximum Achieved Heart Rate (BPM)\"\n",
    "title = \"Overlayed Histograms of Maximum Heart Rate\\n for Heart Disease vs. No Heart Disease\"\n",
    "\n",
    "plt.figure(figsize=(4,6))\n",
    "\n",
    "# Create a histogram with KDE for 'HeartRateMax', grouped by 'DiagnosisYN'\n",
    "sns.histplot(\n",
    "    data=df_combined,\n",
    "    x=att,  # Plot the 'HeartRateMax' column on the x-axis\n",
    "    hue=\"DiagnosisYN\",  # Color the bars by diagnosis (Heart Disease vs. No Heart Disease)\n",
    "    hue_order=[0,1],  # Order of hue labels (No Heart Disease first)\n",
    "    kde=True,  # Display a kernel density estimate on the histogram\n",
    "    bins=20,  # Adjusted number of bins for better clarity\n",
    "    palette=\"Set2\",  # Color palette for the groups\n",
    "    multiple=\"dodge\",  # Place the bars for each group next to each other\n",
    "    alpha=0.5  # Transparency of the bars\n",
    ")\n",
    "\n",
    "# Add title and axis labels\n",
    "plt.title(title, fontsize=12, fontweight='bold')\n",
    "plt.xlabel(att_name, fontsize=12)\n",
    "plt.ylabel(\"Frequency\", fontsize=12)\n",
    "\n",
    "# Customize the legend\n",
    "plt.legend(\n",
    "    title='Diagnosis', \n",
    "    labels=[\"Yes\",\"No\"], \n",
    "    loc='upper right',  # Position the legend in the upper right\n",
    "    fontsize=10\n",
    ")\n",
    "\n",
    "# Adjust layout to avoid clipping of elements\n",
    "plt.subplots_adjust(top=0.92)\n",
    "plt.subplots_adjust(left=0.15)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccb05ee-c2e2-41ac-a0c3-f320dc1ac3b6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Box Plot - HeartRateMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1757dd18-501d-480d-be01-8166ff7a6834",
   "metadata": {},
   "outputs": [],
   "source": [
    "att = \"HeartRateMax\"\n",
    "att_name = \"Maximum Achieved Heart Rate (BPM)\"\n",
    "title = \"Box Plots of Maximum Heart Rate\\n for Heart Disease vs. No Heart Disease\"\n",
    "\n",
    "plt.figure(figsize=(4,5))  # Increased figure size for better clarity\n",
    "\n",
    "# Create a boxplot comparing 'HeartRateMax' for different diagnoses ('Yes' or 'No')\n",
    "sns.boxplot(\n",
    "    data=df_combined,\n",
    "    x=\"DiagnosisYN\",  # x-axis represents diagnosis (No/Yes)\n",
    "    y=att,  # y-axis represents 'HeartRateMax'\n",
    "    hue=\"DiagnosisYN\",  # Color boxes based on diagnosis (Heart Disease vs. No Heart Disease)\n",
    "    palette=\"Set2\",  # Color palette for the boxes\n",
    "    showmeans=True  # Display the mean on the boxplot\n",
    ")\n",
    "\n",
    "# Set the title and axis labels\n",
    "plt.title(title, fontsize=12, fontweight='bold')  # Increased title font size\n",
    "plt.xlabel(\"Diagnosis\", fontsize=12)\n",
    "plt.ylabel(att_name, fontsize=12)  # Increased y-axis label font size\n",
    "\n",
    "# Customize tick labels on x-axis\n",
    "plt.xticks(\n",
    "    ticks=[0, 1], \n",
    "    labels=['No', 'Yes'],  # Replace '0' with 'No' and '1' with 'Yes'\n",
    "    fontsize=12\n",
    ")\n",
    "\n",
    "# Remove the legend as it is not needed for this plot\n",
    "plt.legend([],[],frameon=False)\n",
    "\n",
    "# Adjust the layout to avoid clipping of elements\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.subplots_adjust(left=0.2)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e9dc72-3bdd-4fd7-a21e-cf345c057a3f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Histogram - STDep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf37c4d-7125-40f5-aed0-e437566940f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "att = \"STDep\"\n",
    "att_name = \"ST Depression\"\n",
    "title = \"Overlayed Histograms of ST Depression\\n for Heart Disease vs. No Heart Disease\"\n",
    "\n",
    "plt.figure(figsize=(4,6))\n",
    "\n",
    "# Create a histogram with KDE for 'STDep' for both diagnoses ('Yes' and 'No')\n",
    "sns.histplot(\n",
    "    data=df_combined,\n",
    "    x=att,  # x-axis represents 'STDep'\n",
    "    hue=\"DiagnosisYN\",  # Color by diagnosis (Heart Disease vs. No Heart Disease)\n",
    "    hue_order=[0,1],  # Order of hue categories (No = 0, Yes = 1)\n",
    "    kde=True,  # Include KDE for smoothed distribution\n",
    "    bins=20,  # Adjusted number of bins for better resolution\n",
    "    palette=\"Set2\",  # Color palette for the histogram\n",
    "    multiple=\"dodge\",  # Display bars side by side\n",
    "    alpha=0.5  # Transparency level for the bars\n",
    ")\n",
    "\n",
    "# Set the title and axis labels\n",
    "plt.title(title, fontsize=12, fontweight='bold')  # Increased title font size\n",
    "plt.xlabel(att_name, fontsize=12)\n",
    "plt.ylabel(\"Frequency\", fontsize=12)\n",
    "\n",
    "# Customize the legend\n",
    "plt.legend(\n",
    "    title='Diagnosis', \n",
    "    labels=[\"Yes\",\"No\"], \n",
    "    loc='upper right',\n",
    "    fontsize=12  # Increased font size for legend\n",
    ")\n",
    "\n",
    "# Adjust layout to avoid clipping\n",
    "plt.subplots_adjust(top=0.8)\n",
    "plt.subplots_adjust(left=0.15)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f413ba-742d-438e-9b70-b00af83190f3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Box Plot - STDep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9b10c1-b4bc-41ac-bc75-1c7489f5d31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "att = \"STDep\"\n",
    "att_name = \"ST Depression\"\n",
    "title = \"Box Plots of ST Depression\\n for Heart Disease vs. No Heart Disease\"\n",
    "\n",
    "plt.figure(figsize=(3,4))\n",
    "\n",
    "# Create a box plot to show the distribution of 'STDep' for each diagnosis group\n",
    "sns.boxplot(\n",
    "    data=df_combined,\n",
    "    x=\"DiagnosisYN\",  # x-axis represents diagnosis categories (No vs. Yes)\n",
    "    y=att,  # y-axis represents 'STDep'\n",
    "    hue=\"DiagnosisYN\",  # Color by diagnosis (Heart Disease vs. No Heart Disease)\n",
    "    palette=\"Set2\",  # Color palette for the plot\n",
    "    showmeans=True  # Show the mean value in the box plot\n",
    ")\n",
    "\n",
    "# Set the title and axis labels with increased font size\n",
    "plt.title(title, fontsize=12, fontweight='bold')  # Increased title font size\n",
    "plt.xlabel(\"Diagnosis\", fontsize=14)  # Increased label font size\n",
    "plt.ylabel(att_name, fontsize=14)  # Increased label font size\n",
    "\n",
    "# Customize x-axis ticks and labels\n",
    "plt.xticks(\n",
    "    ticks=[0, 1],  # x-axis positions\n",
    "    labels=['No', 'Yes'],  # Labels for the diagnosis categories\n",
    "    fontsize=12\n",
    ")\n",
    "\n",
    "# Remove the legend as it's not needed for this box plot\n",
    "plt.legend([], [], frameon=False)\n",
    "\n",
    "# Adjust layout to avoid clipping\n",
    "plt.subplots_adjust(top=0.8)\n",
    "plt.subplots_adjust(left=0.15)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7456b63c-441c-4651-a3b9-38f89cdfddc6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.3 Data Exploration - Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76decc00-5375-4610-9fda-b2f95acfa316",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Correlation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724f8993-9e93-48fd-a9f8-173273f74edf",
   "metadata": {},
   "source": [
    "Generate a heatmap of the correlation matrix for numerical features in the dataset. The correlations are annotated inside the heatmap with two decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f1d673-532d-490c-b8a0-c53541ef8977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix for selected numerical columns\n",
    "corr_matrix = df_combined[columns_for_numerical].corr()\n",
    "\n",
    "# Set up the figure for the heatmap\n",
    "plt.figure(figsize=(7,7))  # Adjusted figure size for clearer view\n",
    "\n",
    "# Create the heatmap of the correlation matrix\n",
    "sns.heatmap(\n",
    "    corr_matrix,              # Data to plot (correlation matrix)\n",
    "    annot=True,               # Annotate the cells with correlation values\n",
    "    fmt=\".2f\",                # Format for displaying correlation values\n",
    "    cmap=\"coolwarm\",          # Colormap for the heatmap\n",
    "    linewidths=0.5,           # Line width between the cells\n",
    "    vmin=-1, vmax=1,          # Color scale limits (min and max values)\n",
    "    square=True,              # Ensure the heatmap is square-shaped\n",
    "    cbar_kws={\"shrink\": .8}   # Shrink color bar for better visibility\n",
    ")\n",
    "\n",
    "# Set the title of the plot\n",
    "plt.title(\"Correlation Matrix of Numerical Features\", fontsize=12)\n",
    "\n",
    "# Adjust the layout to avoid clipping of labels and titles\n",
    "plt.subplots_adjust(top=0.95)\n",
    "plt.subplots_adjust(left=0.2)\n",
    "\n",
    "# Display the heatmap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fa47e3-8898-4bdd-9792-eb8d33e18002",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Point Biserial Correlation Coefficient Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b522868-670a-4870-a5f3-bae2159f78b9",
   "metadata": {},
   "source": [
    "This section calculates the point biserial correlation coefficient between each numerical variable and the target variable `DiagnosisYN` (which indicates the presence of heart disease). The point biserial correlation is used to measure the strength and direction of the association between a continuous and a binary variable.\n",
    "\n",
    "The results are displayed as a table with the correlation coefficient and the corresponding p-value for each numerical feature. This is useful for identifying which continuous variables have a significant relationship with the presence of heart disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a419de2d-4481-4b13-bfd9-fdf008a45899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store results\n",
    "pointbi_list = []\n",
    "\n",
    "# Loop through each numerical column in the dataset\n",
    "for col in columns_for_numerical:\n",
    "    # Calculate point-biserial correlation and p-value between the numerical column and 'DiagnosisYN'\n",
    "    correlation, p_value = pointbiserialr(df_combined[col], df_combined['DiagnosisYN'])\n",
    "        \n",
    "    # Append the results (column name, correlation, and p-value) to the list\n",
    "    pointbi_list.append([col, correlation, p_value])\n",
    "\n",
    "# Create a DataFrame to store the results for better visualisation\n",
    "df_pointbi = pd.DataFrame(pointbi_list, columns=[\"Variable\", \"Correlation\", \"P-value\"])\n",
    "\n",
    "# Display the resulting DataFrame in a clean format\n",
    "df_pointbi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f009da6c-b1de-4c91-9a99-c8bcaf7327a9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Visualisation of Point Biserial Correlation Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d756bfdf-41e6-4d32-84b6-c1338cbc41f6",
   "metadata": {},
   "source": [
    "This section visualises the point biserial correlation coefficients between the numerical features and the target variable `DiagnosisYN` using a bar plot. Each bar represents the correlation between a numerical feature and the diagnosis outcome (whether or not the individual has heart disease). The y-axis displays the correlation coefficients ranging from -1 to 1, indicating the strength and direction of the relationship.\n",
    "\n",
    "The visualisation helps to quickly identify which features have stronger associations with heart disease diagnosis and the nature of these relationships (positive or negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae15b80-08e1-4c41-b203-a05497f6101e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the point biserial correlation coefficients with a bar plot\n",
    "plt.figure(figsize=(4, 5))\n",
    "\n",
    "# Create a bar plot for the correlation coefficients of each numerical feature with DiagnosisYN\n",
    "sns.barplot(\n",
    "    x=df_pointbi[\"Variable\"],  # Numerical features\n",
    "    y=df_pointbi[\"Correlation\"],  # Correlation coefficients\n",
    "    color='skyblue',  # Bar color\n",
    "    data=df_pointbi  # Data for the plot\n",
    ")\n",
    "\n",
    "# Set the title for the plot\n",
    "plt.title(\"Point Biserial Correlation Coefficients with DiagnosisYN\", fontsize=10, fontweight='bold')\n",
    "\n",
    "# Set the x-axis label and adjust the font size\n",
    "plt.xlabel('Numerical Features', fontsize=12)\n",
    "\n",
    "# Rotate the x-axis labels to avoid overlap and adjust the font size\n",
    "plt.xticks(rotation=60, fontsize=10)\n",
    "\n",
    "# Set y-axis limits to ensure the correlation coefficients are within the range [-1, 1]\n",
    "plt.ylim(-1, 1)\n",
    "\n",
    "# Adjust the layout for better spacing\n",
    "plt.subplots_adjust(left=0.25, bottom=0.25)\n",
    "\n",
    "# Set the y-axis label for correlation coefficients\n",
    "plt.ylabel('Correlation Coefficient', fontsize=10)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1a31a7-fc4e-4516-a3e3-e9dccad0386a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### PairGrid Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818435a1-9924-4b04-ae7a-8cbd1a306e84",
   "metadata": {},
   "source": [
    "This code creates a PairGrid visualisation to explore relationships between continuous numerical variables in the dataset. The grid displays histograms for individual variables and scatter plots for pairwise comparisons, with the colour representing whether the patient has heart disease (DiagnosisYN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897d73dd-064f-4917-ad4f-5b0301957dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PairGrid for continuous numerical variables, excluding \"ColouredMV\"\n",
    "ax = sns.PairGrid(\n",
    "    df_combined.drop([\"ColouredMV\"], axis=1),  # Drop \"ColouredMV\" column\n",
    "    hue=\"DiagnosisYN\",  # Colour by DiagnosisYN\n",
    "    hue_order=[0, 1]    # Ensure correct order for hue (No = 0, Yes = 1)\n",
    ")\n",
    "\n",
    "# Apply histograms to diagonal elements (individual variable distributions)\n",
    "ax.map_diag(sns.histplot)\n",
    "\n",
    "# Apply scatter plots to off-diagonal elements (pairwise comparisons)\n",
    "ax.map_offdiag(sns.scatterplot)\n",
    "\n",
    "# Add legend and set title\n",
    "ax.add_legend()\n",
    "ax.fig.suptitle(\"Pair Grid of Continuous Numerical Variables\", fontsize=10, fontweight='bold')\n",
    "\n",
    "# Adjust layout to prevent overlap and clipping\n",
    "plt.subplots_adjust(top=0.95)\n",
    "plt.tight_layout()  # Ensure elements fit well into the plot area\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1df8ca-45e7-4983-88a5-9a385a638f55",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Chi-squared test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d86fc4-19fd-4756-80d4-087afbab3bc3",
   "metadata": {},
   "source": [
    "This code calculates the Chi-squared test for each categorical variable against the DiagnosisYN variable (heart disease diagnosis). The test checks whether there is a significant association between categorical variables and heart disease diagnosis. The results are stored and displayed in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201d4f24-0fd0-495c-90b6-a5125be29bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'ColouredMV' to a categorical variable with ordered categories\n",
    "# The column 'ColouredMV' contains multiple values, and we want to treat it as a categorical variable with specific order.\n",
    "df_combined[\"ColouredMVCat\"] = pd.Categorical(df_combined[\"ColouredMV\"], categories=[0, 1, 2, 3], ordered=True)\n",
    "\n",
    "# Check the dtype of the new categorical column to verify the conversion\n",
    "print(df_combined[\"ColouredMVCat\"].dtype)  # This will print the dtype to confirm the conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d4d029-5834-4f40-b34f-16eff005240a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of categorical variables to check against DiagnosisYN\n",
    "columns_for_chi = [\n",
    "    \"Sex\", \n",
    "    \"ChestPain\", \n",
    "    \"FastingBS\", \n",
    "    \"RestingECG\", \n",
    "    \"ExeAngina\", \n",
    "    \"STSlope\", \n",
    "    \"Thalass\", \n",
    "    \"ColouredMVCat\"\n",
    "]\n",
    "\n",
    "chi_list = []\n",
    "\n",
    "# Loop through each categorical variable and perform the Chi-squared test\n",
    "for cat in columns_for_chi:\n",
    "    # Create a contingency table for the categorical variable vs DiagnosisYN\n",
    "    contingency_table = pd.crosstab(df_combined[cat], df_combined['DiagnosisYN'])\n",
    "    \n",
    "    # Perform the Chi-squared test\n",
    "    chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "    # Output the results with formatted p-value\n",
    "    print(f\"For {cat}:\")\n",
    "    print(f\"Chi-squared statistic: {chi2:.4f}\")\n",
    "    print(f\"P-value: {p:.4f}\")\n",
    "    print(f\"Degrees of freedom: {dof}\")\n",
    "    print(f\"Expected frequencies:\\n{expected}\")\n",
    "    \n",
    "    # Interpretation based on p-value\n",
    "    if p < 0.05:\n",
    "        print(\"The result is statistically significant (reject the null hypothesis).\\n\")\n",
    "    else:\n",
    "        print(\"The result is not statistically significant (fail to reject the null hypothesis).\\n\")\n",
    "    \n",
    "    # Append the results to the list\n",
    "    chi_list.append([cat, chi2, dof, p])\n",
    "\n",
    "# Display the results in a DataFrame\n",
    "df_chi = pd.DataFrame(chi_list, columns=[\"Variable\", \"Chi-squared\", \"Degrees of Freedom\", \"P-value\"])\n",
    "df_chi.style.hide(axis=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c89a086-51b1-450a-a121-7fa2c74be919",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.4 Data Exploration - Decision Tree & Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32223ac0-9e53-4559-965f-85376da79d3d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2ecd2a-19ff-4de0-b0c5-b8361d8d676a",
   "metadata": {},
   "source": [
    "Train a Decision Tree classifier on categorical variables to predict heart disease diagnosis (DiagnosisYN). The decision tree is visualised to understand how different categorical variables are used to classify patients into heart disease categories (True/False). The plot helps in interpreting the decision-making process of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e15208-31fe-4b6f-ab90-dc217ee09fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of features used for training the decision tree model\n",
    "features_for_tree = [\n",
    "    \"Sex\", \n",
    "    \"ChestPain\", \n",
    "    \"FastingBS\", \n",
    "    \"RestingECG\", \n",
    "    \"ExeAngina\", \n",
    "    \"STSlope\", \n",
    "    \"Thalass\", \n",
    "    \"ColouredMVCat\"\n",
    "]\n",
    "\n",
    "# Train the Decision Tree classifier\n",
    "clf = DecisionTreeClassifier(random_state=42).fit(\n",
    "    X=df_combined[features_for_tree],  # Feature data\n",
    "    y=df_combined[\"DiagnosisYN\"]       # Target variable (heart disease diagnosis)\n",
    ")\n",
    "\n",
    "# Create a plot of the trained decision tree\n",
    "plt.figure(figsize=(80, 20))  # Adjusted figure size for better readability\n",
    "\n",
    "# Visualise the decision tree\n",
    "plot_tree(\n",
    "    clf,  # Decision tree classifier\n",
    "    filled=True,  # Colour the nodes based on the majority class\n",
    "    max_depth=11,  # Limit the depth for simplicity\n",
    "    feature_names=features_for_tree,  # Feature names used in the model\n",
    "    class_names=[\"No\", \"Yes\"],  # Heart disease diagnosis (No, Yes)\n",
    "    label='all',  # Display all labels (class, samples, value, etc.)\n",
    "    fontsize=10,  # Font size for labels\n",
    "    impurity=False  # Don't show impurity values\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659db0c6-3c7a-4f29-9348-39173b202e40",
   "metadata": {},
   "source": [
    "Perform a GridSearchCV to find the optimal number of leaf nodes for a Decision Tree classifier by evaluating the model's performance across different values for max_leaf_nodes. The optimal number of leaf nodes is determined by selecting the model that achieves the highest test score. Afterward, the decision tree is visualised with the best number of leaf nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d19fc6-b3c3-4eb6-a658-eb01ca98bce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for GridSearchCV\n",
    "parameters = {'max_leaf_nodes': range(3, 20)}  # Searching for optimal number of leaf nodes\n",
    "\n",
    "# Initialize GridSearchCV with Decision Tree classifier and defined parameters\n",
    "clf = GridSearchCV(DecisionTreeClassifier(random_state=42), parameters, n_jobs=4)  # Random state for reproducibility\n",
    "clf.fit(X=df_combined[features_for_tree], y=df_combined[\"DiagnosisYN\"])\n",
    "\n",
    "# Get the best model with the optimal leaf nodes\n",
    "tree_model = clf.best_estimator_\n",
    "\n",
    "# Print the best score and the corresponding parameters\n",
    "print(\"Best score was {:.4f} at {}\".format(clf.best_score_, clf.best_params_))\n",
    "\n",
    "# Plot the relationship between the number of leaf nodes and test score\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(3, 20), clf.cv_results_['mean_test_score'], color='b', marker='o')  # Plot mean test scores\n",
    "plt.xlabel('Max Number of Leaf Nodes', fontsize=12)  # X-axis label\n",
    "plt.ylabel('Test Score', fontsize=12)  # Y-axis label\n",
    "plt.title('Test Score vs. Max Leaf Nodes', fontsize=14, fontweight='bold')  # Plot title\n",
    "plt.grid(True)  # Add grid for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15a37c7-1193-41cd-87fe-ae7b42a925c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new decision tree with the optimal number of leaf nodes (7 in this case)\n",
    "tree_model.set_params(max_leaf_nodes=7)  # Set the leaf nodes to 7 as per the model\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot the decision tree with the new leaf nodes\n",
    "plot_tree(\n",
    "    tree_model, \n",
    "    filled=True, \n",
    "    max_depth=5, \n",
    "    feature_names=features_for_tree, \n",
    "    class_names=[\"No\", \"Yes\"],\n",
    "    label='all', \n",
    "    fontsize=10, \n",
    "    impurity=False\n",
    ")\n",
    "\n",
    "plt.title('Decision Tree Model with 7 Leaf Nodes', fontsize=14, fontweight='bold')  # Plot title\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c934e8c4-a6d2-4bdb-916a-f683b80c60ff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1b9182-93b0-4348-b5fb-be82b1ed1eb9",
   "metadata": {},
   "source": [
    "Implement a Naive Bayes classifier using categorical data to predict the likelihood of a diagnosis. The model is evaluated on 500 random splits of the data (using different random seeds) to assess the accuracy of predictions on the test set. The accuracy scores are collected for further analysis of the modelâ€™s performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f878fd0-fa23-424c-a1fa-dec6042ef010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into features for Naive Bayes classifier\n",
    "columns_for_nb = [\n",
    "    \"Sex\",\n",
    "    \"ChestPain\",\n",
    "    \"FastingBS\",\n",
    "    \"RestingECG\",\n",
    "    \"ExeAngina\",\n",
    "    \"STSlope\",\n",
    "    \"Thalass\",\n",
    "    \"ColouredMVCat\"\n",
    "]\n",
    "\n",
    "X = df_combined[columns_for_nb]  # Feature variables\n",
    "y = df_combined[\"Diagnosis\"]     # Target variable\n",
    "\n",
    "scores = []  # List to store accuracy scores\n",
    "\n",
    "# Loop for 500 random splits to evaluate accuracy\n",
    "for seed in range(1, 501):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "    \n",
    "    # Initialize and train the Naive Bayes classifier\n",
    "    model = CategoricalNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set and calculate accuracy\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Append the accuracy score to the list\n",
    "    scores.append(score)\n",
    "\n",
    "# Convert the list of scores to a numpy array for easier analysis\n",
    "scores = np.array(scores)\n",
    "\n",
    "# Print the summary statistics of the accuracy scores\n",
    "print(f\"Mean accuracy: {scores.mean() * 100:.2f}%\")\n",
    "print(f\"Standard deviation of accuracy: {scores.std() * 100:.2f}%\")\n",
    "\n",
    "# Optionally: plot the distribution of accuracy scores\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(scores, bins=30, color='skyblue', edgecolor='black')\n",
    "plt.title(\"Distribution of Accuracy Scores for Naive Bayes Classifier\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Accuracy', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aa5d30-53bc-46bc-9249-b24d176428fd",
   "metadata": {},
   "source": [
    "Visualises the distribution of these scores using a box plot, which displays the spread of accuracy scores along with the mean. This helps assess the consistency of the classifier's performance across multiple random seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fc167a-108b-4fb8-9597-4a709386695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store accuracy scores in a DataFrame and convert to percentage\n",
    "accuracy_scores_df = pd.DataFrame(scores, columns=[\"Score\"])\n",
    "accuracy_scores_df[\"Score\"] = accuracy_scores_df[\"Score\"] * 100  # Convert to percentage\n",
    "\n",
    "# Display the DataFrame with accuracy scores\n",
    "accuracy_scores_df\n",
    "\n",
    "# Create the box plot for accuracy scores\n",
    "plt.figure(figsize=(5, 2))  # Slightly larger figure for better readability\n",
    "ax = sns.boxplot(\n",
    "    x=accuracy_scores_df[\"Score\"],\n",
    "    showmeans=True\n",
    ")\n",
    "\n",
    "# Set title and labels\n",
    "plt.title(\"Accuracy Scores for Naive Bayes Classifier \\nOver 500 Seeds\", fontsize=12, fontweight='bold')\n",
    "plt.xlabel(\"Accuracy Score (%)\", fontsize=10)  # Clarify that this is in percentage\n",
    "plt.xlim(0, 100)  # Set x-axis limits to 0-100 for percentage scale\n",
    "\n",
    "# Improve axis labels and ticks\n",
    "plt.xticks(fontsize=12)\n",
    "plt.tight_layout()  # Adjust layout to avoid clipping\n",
    "plt.subplots_adjust(left=0.1)  # Adjust left margin for aesthetics\n",
    "\n",
    "# Remove the legend, since it's not needed\n",
    "plt.legend([],[], frameon=False)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce73069-84c8-4228-99ad-7a6617db4f8b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.4 Data Exploration - Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f98dd7-d0cd-4616-a949-62b03624b4b1",
   "metadata": {},
   "source": [
    "#### Logit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cd7080-5331-4ca7-8051-09a0008a1694",
   "metadata": {},
   "source": [
    "Fit a logistic regression model using statsmodels to assess the significance of various features in predicting the likelihood of heart disease. The model evaluates multiple predictors, including both continuous and categorical variables. The coefficients, p-values, and confidence intervals are extracted and stored in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff12bd7c-c091-4d55-92ae-5c7b458df5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DiagnosisYN to integer (binary)\n",
    "df_combined[\"DiagnosisYNInt\"] = df_combined[\"DiagnosisYN\"].astype(\"int64\")\n",
    "\n",
    "# Define the logistic regression formula\n",
    "formula = \"\"\"\n",
    "DiagnosisYNInt ~ \n",
    "Age + \n",
    "C(Sex) + \n",
    "C(ChestPain) + \n",
    "RestingBP + \n",
    "Chol + \n",
    "C(FastingBS) + \n",
    "C(RestingECG) + \n",
    "HeartRateMax + \n",
    "C(ExeAngina) + \n",
    "STDep + \n",
    "C(STSlope) + \n",
    "ColouredMV + \n",
    "C(Thalass)\n",
    "\"\"\"\n",
    "\n",
    "# Fit the logistic regression model\n",
    "mod_2 = smf.logit(formula, data=df_combined)\n",
    "res_2 = mod_2.fit()\n",
    "\n",
    "# Display the summary of the model\n",
    "print(res_2.summary())\n",
    "\n",
    "# Extract coefficients, p-values, and confidence intervals\n",
    "coefficients = res_2.params\n",
    "p_values = res_2.pvalues\n",
    "conf_int = res_2.conf_int()\n",
    "\n",
    "# Create a DataFrame for results\n",
    "results_df = pd.DataFrame({\n",
    "    \"Coefficient\": coefficients,\n",
    "    \"P-Value\": p_values,\n",
    "    \"Conf_Int_Lower\": conf_int[0],\n",
    "    \"Conf_Int_Upper\": conf_int[1],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77edb266-be54-4308-89dc-ce1e0d85cd2e",
   "metadata": {},
   "source": [
    "The categorical features are transformed into binary groups (0 or 1) to facilitate the analysis. A logistic regression model is then fitted using these transformed features and continuous variables. The results, including coefficients, p-values, and confidence intervals, are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9494bc-969d-4235-afd9-6cfa4f94647d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform categorical features into binary groups based on specific thresholds\n",
    "df_combined[\"ChestPainGroup\"] = np.where(df_combined[\"ChestPain\"].isin([1, 2, 3]), 0, 1)\n",
    "df_combined[\"ChestPainGroup\"] = pd.Categorical(df_combined[\"ChestPainGroup\"], categories=[0, 1], ordered=False)\n",
    "\n",
    "df_combined[\"RestingECGGroup\"] = np.where(df_combined[\"RestingECG\"].isin([0]), 0, 1)\n",
    "df_combined[\"RestingECGGroup\"] = pd.Categorical(df_combined[\"RestingECGGroup\"], categories=[0, 1], ordered=False)\n",
    "\n",
    "df_combined[\"ThalassGroup\"] = np.where(df_combined[\"Thalass\"].isin([3, 6]), 0, 1)\n",
    "df_combined[\"ThalassGroup\"] = pd.Categorical(df_combined[\"ThalassGroup\"], categories=[0, 1], ordered=False)\n",
    "\n",
    "df_combined[\"ColouredMVGroup\"] = np.where(df_combined[\"ColouredMV\"].isin([0]), 0, 1)\n",
    "df_combined[\"ColouredMVGroup\"] = pd.Categorical(df_combined[\"ColouredMVGroup\"], categories=[0, 1], ordered=False)\n",
    "\n",
    "df_combined[\"STSlopeGroup\"] = np.where(df_combined[\"STSlope\"].isin([2]), 0, 1)\n",
    "df_combined[\"STSlopeGroup\"] = pd.Categorical(df_combined[\"STSlopeGroup\"], categories=[0, 1], ordered=False)\n",
    "\n",
    "# Define the logistic regression formula with transformed binary features\n",
    "formula = \"\"\"\n",
    "DiagnosisYNInt ~ \n",
    "Age + \n",
    "C(Sex) + \n",
    "C(ChestPainGroup) + \n",
    "RestingBP + \n",
    "Chol + \n",
    "HeartRateMax + \n",
    "C(ExeAngina) + \n",
    "STDep + \n",
    "C(STSlopeGroup) + \n",
    "C(ColouredMVGroup) + \n",
    "C(ThalassGroup)\n",
    "\"\"\"\n",
    "\n",
    "# Fit the logistic regression model\n",
    "mod_2 = smf.logit(formula, data=df_combined)\n",
    "res_2 = mod_2.fit()\n",
    "\n",
    "# Display the summary of the model\n",
    "print(res_2.summary())\n",
    "\n",
    "# Extract coefficients, p-values, and confidence intervals\n",
    "coefficients = res_2.params\n",
    "p_values = res_2.pvalues\n",
    "conf_int = res_2.conf_int()\n",
    "\n",
    "# Create a DataFrame for results\n",
    "results_df = pd.DataFrame({\n",
    "    \"Coefficient\": coefficients,\n",
    "    \"P-Value\": p_values,\n",
    "    \"Conf_Int_Lower\": conf_int[0],  # Lower bound of confidence interval\n",
    "    \"Conf_Int_Upper\": conf_int[1],  # Upper bound of confidence interval\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaafbda-0d38-4584-9050-f22d7690f2ac",
   "metadata": {},
   "source": [
    "## 5. SVM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42e96d7-aa20-41d2-9a37-e3fc3ccf2372",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5.1 Creating Dummy Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbba8d1f-b9ea-45e4-bad5-098eb8ca12f0",
   "metadata": {},
   "source": [
    "In this section, we create dummy variables for the features that will be used in a Support Vector Classifier (SVC) model. This includes converting categorical variables into binary features using one-hot encoding, removing unnecessary columns, and converting the data types to ensure compatibility with the SVC model. The result is a cleaned and processed dataset ready for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1771418-8027-458f-9746-1475d9c20894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data types to see which columns require conversion\n",
    "df_combined.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af40050-715d-4217-8029-6cab4e2b6910",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create dummy variables for categorical features and drop unnecessary columns\n",
    "df_combined_svc = pd.get_dummies(df_combined, columns=[\n",
    "    \"ChestPain\", \n",
    "    \"RestingECG\", \n",
    "    \"STSlope\", \n",
    "    \"ColouredMVCat\", \n",
    "    \"Thalass\"\n",
    "], drop_first=False)\n",
    "\n",
    "# Drop columns that are not needed for the model\n",
    "df_combined_svc = df_combined_svc.drop(columns=[\n",
    "    \"SexMF\",  # Dropped as we will treat Sex as binary (0/1)\n",
    "    \"DiagnosisYNInt\",  # This column is redundant with DiagnosisYN\n",
    "    \"ChestPainGroup\",  # Grouped versions of ChestPain not needed\n",
    "    \"RestingECGGroup\",  # Similar to ChestPainGroup, not required\n",
    "    \"ThalassGroup\",  # Grouped version of Thalass not required\n",
    "    \"ColouredMVGroup\",  # Grouped version of ColouredMV not needed\n",
    "    \"STSlopeGroup\",  # Grouped version of Slope not necessary\n",
    "    \"Diagnosis\"  # This is the target, which will be kept separately in y\n",
    "])\n",
    "\n",
    "# Convert relevant columns to appropriate data types for SVC model\n",
    "df_combined_svc = df_combined_svc.astype({\n",
    "    \"Age\": \"int64\",\n",
    "    \"Sex\": \"bool\",  # Sex is binary (0 or 1)\n",
    "    \"RestingBP\": \"int64\",\n",
    "    \"Chol\": \"int64\",\n",
    "    \"FastingBS\": \"bool\",  # FastingBS is binary\n",
    "    \"HeartRateMax\": \"int64\",\n",
    "    \"ExeAngina\": \"bool\",  # ExeAngina is binary\n",
    "    \"STDep\": \"float64\",\n",
    "    \"DiagnosisYN\": \"bool\"  # Target variable is binary (0 or 1)\n",
    "})\n",
    "\n",
    "# Confirm the changes in data types\n",
    "df_combined_svc.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85770c87-ac8d-412e-8ca5-b1308deb6106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all features for the SVC model\n",
    "all_svc_features = [\n",
    "    'Age',\n",
    "    'Sex',\n",
    "    'ChestPain_1',\n",
    "    'ChestPain_2',\n",
    "    'ChestPain_3',\n",
    "    'ChestPain_4',\n",
    "    'RestingBP',\n",
    "    'Chol',\n",
    "    'FastingBS',\n",
    "    'RestingECG_0',\n",
    "    'RestingECG_1',\n",
    "    'RestingECG_2',\n",
    "    'HeartRateMax',\n",
    "    'ExeAngina',\n",
    "    'STDep',\n",
    "    'STSlope_1',\n",
    "    'STSlope_2',\n",
    "    'STSlope_3',\n",
    "    'ColouredMVCat_0',\n",
    "    'ColouredMVCat_1',\n",
    "    'ColouredMVCat_2',\n",
    "    'ColouredMVCat_3',\n",
    "    'Thalass_3',\n",
    "    'Thalass_6',\n",
    "    'Thalass_7',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53be882e-85be-46ad-aac1-aebac2ec118a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5.2 Linear vs. RBF vs. Poly // Unscaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7ebea0-9e4f-4e30-852d-01119c6d9528",
   "metadata": {},
   "source": [
    "In this section, we compare the performance of three different SVC kernel types (Linear, RBF, and Poly) without scaling the features. We start by implementing the model with a linear kernel, training it on the selected features, and calculating the accuracy. The accuracy scores are recorded for each seed value (from 1 to 100) to observe the stability of the model's performance. Afterward, we will compare these results to the other kernel types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4892c648-1e07-4f5e-928d-574a5272a5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to train and evaluate the model for a given kernel type\n",
    "def evaluate_svc_kernel(kernel_type, X, y, n_runs=100):\n",
    "    accuracy_list = []\n",
    "    for seed in range(1, n_runs + 1):\n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "        \n",
    "        # SVC model with the specified kernel\n",
    "        model = SVC(kernel=kernel_type)\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict the labels for the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "       \n",
    "        # Calculate the accuracy score\n",
    "        accuracy_svc = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # Append the accuracy score\n",
    "        accuracy_list.append(accuracy_svc)\n",
    "    \n",
    "    # Return the accuracy list and average accuracy\n",
    "    average_acc = mean(accuracy_list)\n",
    "    return accuracy_list, average_acc\n",
    "\n",
    "# Define features and target variable\n",
    "X = df_combined_svc[all_svc_features]\n",
    "y = df_combined_svc[\"DiagnosisYN\"]\n",
    "\n",
    "# Evaluate each kernel and store results\n",
    "kernels = ['linear', 'rbf', 'poly']\n",
    "kernel_results = {}\n",
    "\n",
    "for kernel in kernels:\n",
    "    accuracy_list, avg_acc = evaluate_svc_kernel(kernel, X, y)\n",
    "    kernel_results[kernel] = {\n",
    "        'accuracy_list': accuracy_list,\n",
    "        'average_accuracy': avg_acc\n",
    "    }\n",
    "    print(f\"{kernel.capitalize()} Kernel Accuracy: {avg_acc * 100:.2f}%\\n\")\n",
    "\n",
    "# Convert results into DataFrame for easy comparison\n",
    "df_kernel_comparison = pd.DataFrame({\n",
    "    kernel: results['accuracy_list'] for kernel, results in kernel_results.items()\n",
    "})\n",
    "\n",
    "df_kernel_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c89e13-b8ef-450e-b5f9-5ab190bf5a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the DataFrame to prepare for plotting\n",
    "df_kernel_comparison_melted = pd.melt(df_kernel_comparison)\n",
    "df_kernel_comparison_melted.columns = [\"Kernel\", \"AccuracyScore\"]\n",
    "\n",
    "# Create the boxplot for visual comparison\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(data=df_kernel_comparison_melted, x=\"Kernel\", y=\"AccuracyScore\", palette=\"Set2\", hue=\"Kernel\", showmeans=True)\n",
    "plt.title(\"Comparison of Accuracy Scores Based on Kernel Type (Unscaled SVC Model)\", fontsize=14)\n",
    "plt.xlabel(\"Kernel\", fontsize=12)\n",
    "plt.ylabel(\"Accuracy (%)\", fontsize=12)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40c8133-f1ec-4220-941f-49831120b1fa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5.3 Linear vs. RBF vs. Poly // Scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65eeb24-ce7a-4b1b-b074-5a2e31e46d13",
   "metadata": {},
   "source": [
    "We now compare the performance of three different SVC kernel types (Linear, RBF, and Poly) when scaling the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1f6be6-3921-4d45-9ee2-cc2e25e3a925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to train and evaluate the SVC model with a specified kernel type and scaling\n",
    "def evaluate_svc_kernel_scaled(kernel_type, X, y, n_runs=100):\n",
    "    accuracy_list = []\n",
    "    for seed in range(1, n_runs + 1):\n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "        # Standardize the features using StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # Initialize and train the SVC model\n",
    "        model = SVC(kernel=kernel_type)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Predict the labels for the test set and calculate accuracy\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        accuracy_svc = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # Append the accuracy score\n",
    "        accuracy_list.append(accuracy_svc)\n",
    "    \n",
    "    # Return the accuracy list and average accuracy\n",
    "    average_acc = mean(accuracy_list)\n",
    "    return accuracy_list, average_acc\n",
    "\n",
    "# Define features and target variable\n",
    "X = df_combined_svc[all_svc_features]\n",
    "y = df_combined_svc[\"DiagnosisYN\"]\n",
    "\n",
    "# Evaluate each kernel with scaling and store results\n",
    "kernels = ['linear', 'rbf', 'poly']\n",
    "kernel_results_scaled = {}\n",
    "\n",
    "for kernel in kernels:\n",
    "    accuracy_list, avg_acc = evaluate_svc_kernel_scaled(kernel, X, y)\n",
    "    kernel_results_scaled[kernel] = {\n",
    "        'accuracy_list': accuracy_list,\n",
    "        'average_accuracy': avg_acc\n",
    "    }\n",
    "    print(f\"{kernel.capitalize()} Kernel (Scaled) Accuracy: {avg_acc * 100:.2f}%\\n\")\n",
    "\n",
    "# Convert results into DataFrame for easy comparison\n",
    "df_kernel_comparison_scaled = pd.DataFrame({\n",
    "    kernel: results['accuracy_list'] for kernel, results in kernel_results_scaled.items()\n",
    "})\n",
    "\n",
    "df_kernel_comparison_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b35abb-f301-472f-87b9-cbe4e57334ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the DataFrame to prepare for plotting\n",
    "df_kernel_comparison_scaled_melted = pd.melt(df_kernel_comparison_scaled)\n",
    "df_kernel_comparison_scaled_melted.columns = [\"Kernel\", \"AccuracyScore\"]\n",
    "\n",
    "# Create the boxplot for visual comparison\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(data=df_kernel_comparison_scaled_melted, x=\"Kernel\", y=\"AccuracyScore\", palette=\"Set2\", hue=\"Kernel\", showmeans=True)\n",
    "plt.title(\"Comparison of Accuracy Scores Based on Kernel Type (Scaled SVC Model)\", fontsize=14)\n",
    "plt.xlabel(\"Kernel\", fontsize=12)\n",
    "plt.ylabel(\"Accuracy (%)\", fontsize=12)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0d99ac-0699-4509-b701-38848fa882b2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5.4 Linear vs. RBF vs. Poly // Scaled // Reduced Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9942e750-07d4-45a5-a159-ed4bebcc742a",
   "metadata": {},
   "source": [
    "We now compare the performance of three different SVC kernel types (Linear, RBF, and Poly) when scaling the features and using a reduced set of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d034695-8185-41ae-bdf4-e239b9abb715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate the SVC model with a specified kernel and scaling\n",
    "def evaluate_svc_kernel_scaled_reduced(kernel_type, X, y, n_runs=100):\n",
    "    accuracy_list = []\n",
    "    for seed in range(1, n_runs + 1):\n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "        # Standardize the features using StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # Initialize and train the SVC model\n",
    "        model = SVC(kernel=kernel_type)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Predict the labels for the test set and calculate accuracy\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        accuracy_svc = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # Append the accuracy score\n",
    "        accuracy_list.append(accuracy_svc)\n",
    "    \n",
    "    # Return the accuracy list and average accuracy\n",
    "    average_acc = mean(accuracy_list)\n",
    "    return accuracy_list, average_acc\n",
    "\n",
    "# Define the reduced features and target variable\n",
    "reduced_svc_features = [\n",
    "    'Age', 'Sex', 'ChestPain_2', 'ChestPain_4', 'RestingBP', 'Chol', 'HeartRateMax',\n",
    "    'ExeAngina', 'STDep', 'STSlope_2', 'ColouredMVCat_0', 'ColouredMVCat_1', 'ColouredMVCat_2',\n",
    "    'ColouredMVCat_3', 'Thalass_3', 'Thalass_7'\n",
    "]\n",
    "\n",
    "X = df_combined_svc[reduced_svc_features]\n",
    "y = df_combined_svc[\"DiagnosisYN\"]\n",
    "\n",
    "# Evaluate each kernel with scaling and store results\n",
    "kernels = ['linear', 'rbf', 'poly']\n",
    "kernel_results_scaled_reduced = {}\n",
    "\n",
    "for kernel in kernels:\n",
    "    accuracy_list, avg_acc = evaluate_svc_kernel_scaled_reduced(kernel, X, y)\n",
    "    kernel_results_scaled_reduced[kernel] = {\n",
    "        'accuracy_list': accuracy_list,\n",
    "        'average_accuracy': avg_acc\n",
    "    }\n",
    "    print(f\"{kernel.capitalize()} Kernel (Scaled) Accuracy: {avg_acc * 100:.2f}%\\n\")\n",
    "\n",
    "# Convert results into DataFrame for easy comparison\n",
    "df_kernel_comparison_scaled_reduced = pd.DataFrame({\n",
    "    kernel: results['accuracy_list'] for kernel, results in kernel_results_scaled_reduced.items()\n",
    "})\n",
    "\n",
    "df_kernel_comparison_scaled_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b77d4a-bdd8-49f0-8aff-af4855a2e5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the DataFrame to prepare for plotting\n",
    "df_kernel_comparison_scaled_reduced_melted = pd.melt(df_kernel_comparison_scaled_reduced)\n",
    "df_kernel_comparison_scaled_reduced_melted.columns = [\"Kernel\", \"AccuracyScore\"]\n",
    "\n",
    "# Create the boxplot for visual comparison\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(data=df_kernel_comparison_scaled_reduced_melted, x=\"Kernel\", y=\"AccuracyScore\", palette=\"Set2\", hue=\"Kernel\", showmeans=True)\n",
    "plt.title(\"Comparison of Accuracy Scores Based on Kernel Type (Scaled SVC Model with Reduced Variables)\", fontsize=14)\n",
    "plt.xlabel(\"Kernel\", fontsize=12)\n",
    "plt.ylabel(\"Accuracy (%)\", fontsize=12)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f522fd-80b3-43c5-8309-98c39b9ca695",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5.5. Linear vs. RBF vs. Poly // Scaled // Reduced Variables // Balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96829970-a978-4e27-b44c-1c31427d87de",
   "metadata": {},
   "source": [
    "To handle any class imbalance, a balanced approach is applied during cross-validation to ensure that each class is equally represented in the training and testing splits. This comparison helps assess how each kernel type performs under these conditions and which is the most effective for the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e282954-2cba-4414-91cd-5b000ea657f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate SVC with balanced class weights and scaling\n",
    "def evaluate_svc_kernel_balanced_scaled(kernel_type, X, y, n_runs=100):\n",
    "    accuracy_list = []\n",
    "    for seed in range(1, n_runs + 1):\n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "        # Standardize the features using StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # Initialize and train the SVC model with class weight balancing\n",
    "        model = SVC(kernel=kernel_type, class_weight='balanced')\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Predict the labels for the test set and calculate accuracy\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        accuracy_svc = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # Append the accuracy score\n",
    "        accuracy_list.append(accuracy_svc)\n",
    "    \n",
    "    # Return the accuracy list and average accuracy\n",
    "    average_acc = mean(accuracy_list)\n",
    "    return accuracy_list, average_acc\n",
    "\n",
    "# Define the reduced features and target variable\n",
    "reduced_svc_features = [\n",
    "    'Age', 'Sex', 'ChestPain_2', 'ChestPain_4', 'RestingBP', 'Chol', 'HeartRateMax',\n",
    "    'ExeAngina', 'STDep', 'STSlope_2', 'ColouredMVCat_0', 'ColouredMVCat_1', 'ColouredMVCat_2',\n",
    "    'ColouredMVCat_3', 'Thalass_3', 'Thalass_7'\n",
    "]\n",
    "\n",
    "X = df_combined_svc[reduced_svc_features]\n",
    "y = df_combined_svc[\"DiagnosisYN\"]\n",
    "\n",
    "# Evaluate each kernel with scaling and class balancing\n",
    "kernels = ['linear', 'rbf', 'poly']\n",
    "kernel_results_balanced_scaled = {}\n",
    "\n",
    "for kernel in kernels:\n",
    "    accuracy_list, avg_acc = evaluate_svc_kernel_balanced_scaled(kernel, X, y)\n",
    "    kernel_results_balanced_scaled[kernel] = {\n",
    "        'accuracy_list': accuracy_list,\n",
    "        'average_accuracy': avg_acc\n",
    "    }\n",
    "    print(f\"{kernel.capitalize()} Kernel (Balanced, Scaled) Accuracy: {avg_acc * 100:.2f}%\\n\")\n",
    "\n",
    "# Convert results into DataFrame for easy comparison\n",
    "df_kernel_comparison_balanced_scaled = pd.DataFrame({\n",
    "    kernel: results['accuracy_list'] for kernel, results in kernel_results_balanced_scaled.items()\n",
    "})\n",
    "\n",
    "df_kernel_comparison_balanced_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73973936-a487-43b2-8fc7-458276aa9858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the DataFrame to prepare for plotting\n",
    "df_kernel_comparison_balanced_scaled_melted = pd.melt(df_kernel_comparison_balanced_scaled)\n",
    "df_kernel_comparison_balanced_scaled_melted.columns = [\"Kernel\", \"AccuracyScore\"]\n",
    "\n",
    "# Create the boxplot for visual comparison\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(data=df_kernel_comparison_balanced_scaled_melted, x=\"Kernel\", y=\"AccuracyScore\", palette=\"Set2\", hue=\"Kernel\", showmeans=True)\n",
    "plt.title(\"Comparison of Accuracy Scores Based on Kernel Type (Scaled SVC Model with Reduced Variables and Balanced Class Weight)\", fontsize=14)\n",
    "plt.xlabel(\"Kernel\", fontsize=12)\n",
    "plt.ylabel(\"Accuracy (%)\", fontsize=12)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ae7da0-d882-4de0-a89c-5db880ace130",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5.6 Linear vs. RBF vs. Poly // Scaled // Reduced Variables // StratKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac4ed0a-ee47-45b6-be46-4a8c720a61b4",
   "metadata": {},
   "source": [
    "We use Stratified K-Fold cross-validation, which preserves the proportion of each class in each fold, making the results more reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fe3ed3-f2fb-4d10-957e-1b0d51ef1090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate SVC kernels with StratifiedKFold cross-validation\n",
    "def evaluate_svc_kernel_stratified_kfold(kernel_type, X, y, n_splits=5, n_runs=100):\n",
    "    accuracy_list = []\n",
    "    \n",
    "    # Create a pipeline for scaling and SVC model\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', SVC(kernel=kernel_type))\n",
    "    ])\n",
    "    \n",
    "    for seed in range(1, n_runs + 1):\n",
    "        # StratifiedKFold for preserving class distribution in splits\n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "        # Perform cross-validation on the pipeline\n",
    "        accuracy_score = cross_val_score(pipeline, X, y, cv=skf, scoring='accuracy')\n",
    "\n",
    "        # Append the mean accuracy score from each fold\n",
    "        accuracy_list.append(accuracy_score.mean())\n",
    "\n",
    "    # Return the accuracy list and average accuracy\n",
    "    average_acc = mean(accuracy_list)\n",
    "    return accuracy_list, average_acc\n",
    "\n",
    "# Define the reduced features and target variable\n",
    "reduced_svc_features = [\n",
    "    'Age', 'Sex', 'ChestPain_2', 'ChestPain_4', 'RestingBP', 'Chol', 'HeartRateMax',\n",
    "    'ExeAngina', 'STDep', 'STSlope_2', 'ColouredMVCat_0', 'ColouredMVCat_1', 'ColouredMVCat_2',\n",
    "    'ColouredMVCat_3', 'Thalass_3', 'Thalass_7'\n",
    "]\n",
    "\n",
    "X = df_combined_svc[reduced_svc_features]\n",
    "y = df_combined_svc[\"DiagnosisYN\"]\n",
    "\n",
    "# Evaluate each kernel with StratifiedKFold cross-validation\n",
    "kernels = ['linear', 'rbf', 'poly']\n",
    "kernel_results_stratified_kfold = {}\n",
    "\n",
    "for kernel in kernels:\n",
    "    accuracy_list, avg_acc = evaluate_svc_kernel_stratified_kfold(kernel, X, y)\n",
    "    kernel_results_stratified_kfold[kernel] = {\n",
    "        'accuracy_list': accuracy_list,\n",
    "        'average_accuracy': avg_acc\n",
    "    }\n",
    "    print(f\"{kernel.capitalize()} Kernel (StratifiedKFold) Accuracy: {avg_acc * 100:.2f}%\\n\")\n",
    "\n",
    "# Convert results into DataFrame for easy comparison\n",
    "df_kernel_comparison_stratified_kfold = pd.DataFrame({\n",
    "    kernel: results['accuracy_list'] for kernel, results in kernel_results_stratified_kfold.items()\n",
    "})\n",
    "\n",
    "df_kernel_comparison_stratified_kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7542d83a-58ee-49cf-82fa-6fba33b7f3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the DataFrame to prepare for plotting\n",
    "df_kernel_comparison_stratified_kfold_melted = pd.melt(df_kernel_comparison_stratified_kfold)\n",
    "df_kernel_comparison_stratified_kfold_melted.columns = [\"Kernel\", \"AccuracyScore\"]\n",
    "\n",
    "# Create the boxplot for visual comparison\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(data=df_kernel_comparison_stratified_kfold_melted, x=\"Kernel\", y=\"AccuracyScore\", palette=\"Set2\", hue=\"Kernel\", showmeans=True)\n",
    "plt.title(\"Comparison of Accuracy Scores Based on Kernel Type, Scaling, Reduced Variables, and StratifiedKFold Validator\", fontsize=14)\n",
    "plt.xlabel(\"Kernel\", fontsize=12)\n",
    "plt.ylabel(\"Accuracy (%)\", fontsize=12)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22765375-0402-43fe-96ba-f011f2fa1d60",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5.7 Linear vs. RBF vs. Poly // Scaled // Reduced Variables // StratShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dce0c3f-f505-44ba-ad95-c77e0613c058",
   "metadata": {},
   "source": [
    "The evaluation is also conducted using Stratified Shuffle Split cross-validation, which randomly splits the dataset into training and test sets while preserving the class distribution in each split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081c2a0e-9944-49e3-9efb-ab795dbaa630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate SVC kernels with StratifiedShuffleSplit cross-validation\n",
    "def evaluate_svc_kernel_stratified_shufflesplit(kernel_type, X, y, n_splits=5, test_size=0.2, n_runs=100):\n",
    "    accuracy_list = []\n",
    "    \n",
    "    # Create a pipeline for scaling and SVC model\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', SVC(kernel=kernel_type))\n",
    "    ])\n",
    "    \n",
    "    for seed in range(1, n_runs + 1):\n",
    "        # StratifiedShuffleSplit for preserving class distribution in splits\n",
    "        sss = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=seed)\n",
    "\n",
    "        # Perform cross-validation on the pipeline\n",
    "        accuracy_score = cross_val_score(pipeline, X, y, cv=sss, scoring='accuracy')\n",
    "\n",
    "        # Append the mean accuracy score from each fold\n",
    "        accuracy_list.append(accuracy_score.mean())\n",
    "\n",
    "    # Return the accuracy list and average accuracy\n",
    "    average_acc = mean(accuracy_list)\n",
    "    return accuracy_list, average_acc\n",
    "\n",
    "# Define the reduced features and target variable\n",
    "reduced_svc_features = [\n",
    "    'Age', 'Sex', 'ChestPain_2', 'ChestPain_4', 'RestingBP', 'Chol', 'HeartRateMax',\n",
    "    'ExeAngina', 'STDep', 'STSlope_2', 'ColouredMVCat_0', 'ColouredMVCat_1', 'ColouredMVCat_2',\n",
    "    'ColouredMVCat_3', 'Thalass_3', 'Thalass_7'\n",
    "]\n",
    "\n",
    "X = df_combined_svc[reduced_svc_features]\n",
    "y = df_combined_svc[\"DiagnosisYN\"]\n",
    "\n",
    "# Evaluate each kernel with StratifiedShuffleSplit cross-validation\n",
    "kernels = ['linear', 'rbf', 'poly']\n",
    "kernel_results_stratified_shufflesplit = {}\n",
    "\n",
    "for kernel in kernels:\n",
    "    accuracy_list, avg_acc = evaluate_svc_kernel_stratified_shufflesplit(kernel, X, y)\n",
    "    kernel_results_stratified_shufflesplit[kernel] = {\n",
    "        'accuracy_list': accuracy_list,\n",
    "        'average_accuracy': avg_acc\n",
    "    }\n",
    "    print(f\"{kernel.capitalize()} Kernel (StratifiedShuffleSplit) Accuracy: {avg_acc * 100:.2f}%\\n\")\n",
    "\n",
    "# Convert results into DataFrame for easy comparison\n",
    "df_kernel_comparison_stratified_shufflesplit = pd.DataFrame({\n",
    "    kernel: results['accuracy_list'] for kernel, results in kernel_results_stratified_shufflesplit.items()\n",
    "})\n",
    "\n",
    "df_kernel_comparison_stratified_shufflesplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d87a72-d339-4078-98ad-637b1cfdb567",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Melt the DataFrame to prepare for plotting\n",
    "df_kernel_comparison_stratified_shufflesplit_melted = pd.melt(df_kernel_comparison_stratified_shufflesplit)\n",
    "df_kernel_comparison_stratified_shufflesplit_melted.columns = [\"Kernel\", \"AccuracyScore\"]\n",
    "\n",
    "# Create the boxplot for visual comparison\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(data=df_kernel_comparison_stratified_shufflesplit_melted, x=\"Kernel\", y=\"AccuracyScore\", palette=\"Set2\", hue=\"Kernel\", showmeans=True)\n",
    "plt.title(\"Comparison of Accuracy Scores Based on Kernel Type, Scaling, Reduced Variables, and StratifiedShuffleSplit Validator\", fontsize=14)\n",
    "plt.xlabel(\"Kernel\", fontsize=12)\n",
    "plt.ylabel(\"Accuracy (%)\", fontsize=12)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190b144b-a039-4ad3-a1f3-89e494bd15bf",
   "metadata": {},
   "source": [
    "### 5.8 GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e12195-61a7-4674-9f14-6b36fa3e8b66",
   "metadata": {},
   "source": [
    "In this section, we use **GridSearchCV** to identify the optimal hyperparameters for an SVC model based on multiple performance metrics: accuracy, recall, precision, and F1 score. \n",
    "\n",
    "The model is evaluated using cross-validation, and the best parameter combinations are found for each score. Additionally, various kernels, class weight options, regularization strengths, gamma values, and PCA component selections are explored through a systematic grid search. This method helps identify the most effective configuration for achieving the best scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda2232d-020b-4c64-9b7c-e8b00caf50ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}  # Initialize dictionary to store results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f121d3-195f-4104-ac12-d038b32e35bc",
   "metadata": {},
   "source": [
    "Function to run the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ee78c8-9feb-4856-bd5d-2fe85162d3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run grid search and return results for different metrics\n",
    "def run_grid_search(X, y, param_grid, score, seed):\n",
    "    \"\"\"\n",
    "    Run GridSearchCV for the given parameters and return the best hyperparameters and scores.\n",
    "    \n",
    "    Args:\n",
    "    X (DataFrame): Feature set for the model.\n",
    "    y (Series): Target labels.\n",
    "    param_grid (dict): Dictionary of hyperparameters for the grid search.\n",
    "    score (str): The metric to optimize when refitting the model (e.g., 'accuracy', 'recall', 'precision', 'f1').\n",
    "    seed (int): Random seed for reproducibility.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: A tuple containing the best parameters (dict) and a DataFrame with cross-validation results.\n",
    "    \"\"\"\n",
    "    # Create the pipeline with scaling, PCA, and SVC\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca', PCA()),\n",
    "        ('svc', SVC())\n",
    "    ])\n",
    "    \n",
    "    # StratifiedKFold for cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    \n",
    "    # Initialize GridSearchCV with cross-validation and scoring metrics\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grid,\n",
    "        cv=skf,\n",
    "        scoring=['accuracy', 'recall', 'precision', 'f1'],\n",
    "        refit=score,  # Refit the model based on recall\n",
    "        verbose=0,       # Set verbosity to 0 for minimal output\n",
    "        n_jobs=-1        # Use all available CPU cores\n",
    "    )\n",
    "    \n",
    "    # Fit the model with grid search\n",
    "    grid_search.fit(X, y)\n",
    "    \n",
    "    # Get the best model from grid search\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Collect cross-validation results and extract relevant columns\n",
    "    cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "    cv_results_filtered = cv_results[[\n",
    "        'param_svc__kernel', \n",
    "        'param_svc__C', \n",
    "        'param_svc__class_weight', \n",
    "        'param_svc__gamma', \n",
    "        'param_pca__n_components',\n",
    "        'mean_test_accuracy',\n",
    "        'mean_test_recall', \n",
    "        'mean_test_precision',\n",
    "        'mean_test_f1'\n",
    "    ]]\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    cv_results_filtered.columns = [\"kernel\", \"C\", \"weight\", \"gamma\", \"pca\", \"accuracy\", \"recall\", \"precision\", \"f1\"]\n",
    "    cv_results_filtered = cv_results_filtered.sort_values(by=score, ascending=False)\n",
    "    # Return the best parameters and filtered cross-validation results\n",
    "    return best_params, cv_results_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3fc84b-37c0-4b72-b482-df2811aa6f05",
   "metadata": {},
   "source": [
    "Running grid search using **Recall** as the score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08aba31a-816a-4c31-bf58-6eaaf38e658d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "X = df_combined_svc[reduced_svc_features]\n",
    "y = df_combined_svc[\"DiagnosisYN\"]\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'scaler': [StandardScaler()],\n",
    "    'svc__kernel': ['linear', 'rbf', 'poly'],\n",
    "    'svc__class_weight': [None, 'balanced'],\n",
    "    'svc__C': [0.05, 0.1, 1, 10],\n",
    "    'svc__gamma': ['scale', 'auto'],\n",
    "    'pca__n_components': [None, 0.80, 0.90, 6, 7]\n",
    "}\n",
    "\n",
    "#####################################\n",
    "# Choose the score for best_params_ #\n",
    "score = 'recall'\n",
    "#####################################\n",
    "\n",
    "# Choose the column for the final table to sort by\n",
    "column = f'best_{score}'\n",
    "\n",
    "# Name the dataframe that will be created\n",
    "df_name = f\"grid_results_{score}\"\n",
    "\n",
    "# Initialize a list to store results\n",
    "results = []\n",
    "\n",
    "# Loop over 100 random seeds for cross-validation\n",
    "for seed in range(1, 101):\n",
    "    # Print which seed is being used\n",
    "    print(f\"Running with random seed: {seed}\")\n",
    "    \n",
    "    # Run the grid search and get the results\n",
    "    best_params, cv_results_filtered = run_grid_search(X, y, param_grid, score, seed)\n",
    "\n",
    "    # Ensure cv_results_filtered is not empty before accessing .iloc[0]\n",
    "    if not cv_results_filtered.empty:\n",
    "        top_row = cv_results_filtered.iloc[0]\n",
    "    \n",
    "        # Append the best results to the results list\n",
    "        results.append({\n",
    "            'seed': seed,\n",
    "            'kernel': top_row['kernel'],\n",
    "            'C': top_row['C'],\n",
    "            'weight': top_row['weight'],\n",
    "            'gamma': top_row['gamma'],\n",
    "            'pca': top_row['pca'],\n",
    "            'best_accuracy': top_row['accuracy'],\n",
    "            'best_recall': top_row['recall'],\n",
    "            'best_precision': top_row['precision'],\n",
    "            'best_f1': top_row['f1']\n",
    "    })\n",
    "\n",
    "        # Print the best hyperparameters for the current seed\n",
    "        print(f\"Best {score}: {top_row[score]:.4f}, Kernel: {top_row['kernel']}, C: {top_row['C']}, Weight: {top_row['weight']}, Gamma: {top_row['gamma']}, PCA: {top_row['pca']}\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"Warning: No valid results for seed {seed}\")\n",
    "        print()\n",
    "\n",
    "results_dict[score] = pd.DataFrame(results).sort_values(by=column, ascending=False)\n",
    "\n",
    "# Display the latest concatenated results for this score\n",
    "print(f\"Displaying all results for {score}:\")\n",
    "display(results_dict[score].head(10))  # Shows the latest results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0a815d-3c93-4708-ab37-ff0bc58d48f4",
   "metadata": {},
   "source": [
    "Running grid search using **accuracy** as the score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8438f2-0dd4-4a76-bf08-e0c9a31d66ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "X = df_combined_svc[reduced_svc_features]\n",
    "y = df_combined_svc[\"DiagnosisYN\"]\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'scaler': [StandardScaler()],\n",
    "    'svc__kernel': ['linear', 'rbf', 'poly'],\n",
    "    'svc__class_weight': [None, 'balanced'],\n",
    "    'svc__C': [0.05, 0.1, 1, 10],\n",
    "    'svc__gamma': ['scale', 'auto'],\n",
    "    'pca__n_components': [None, 0.80, 0.90, 6, 7]\n",
    "}\n",
    "\n",
    "#####################################\n",
    "# Choose the score for best_params_ #\n",
    "score = 'accuracy'\n",
    "#####################################\n",
    "\n",
    "# Choose the column for the final table to sort by\n",
    "column = f'best_{score}'\n",
    "\n",
    "# Name the dataframe that will be created\n",
    "df_name = f\"grid_results_{score}\"\n",
    "\n",
    "# Initialize a list to store results\n",
    "results = []\n",
    "\n",
    "# Loop over 100 random seeds for cross-validation\n",
    "for seed in range(1, 101):\n",
    "    # Print which seed is being used\n",
    "    print(f\"Running with random seed: {seed}\")\n",
    "    \n",
    "    # Run the grid search and get the results\n",
    "    best_params, cv_results_filtered = run_grid_search(X, y, param_grid, score, seed)\n",
    "\n",
    "    # Ensure cv_results_filtered is not empty before accessing .iloc[0]\n",
    "    if not cv_results_filtered.empty:\n",
    "        top_row = cv_results_filtered.iloc[0]\n",
    "    \n",
    "        # Append the best results to the results list\n",
    "        results.append({\n",
    "            'seed': seed,\n",
    "            'kernel': top_row['kernel'],\n",
    "            'C': top_row['C'],\n",
    "            'weight': top_row['weight'],\n",
    "            'gamma': top_row['gamma'],\n",
    "            'pca': top_row['pca'],\n",
    "            'best_accuracy': top_row['accuracy'],\n",
    "            'best_recall': top_row['recall'],\n",
    "            'best_precision': top_row['precision'],\n",
    "            'best_f1': top_row['f1']\n",
    "    })\n",
    "\n",
    "        # Print the best hyperparameters for the current seed\n",
    "        print(f\"Best {score}: {top_row[score]:.4f}, Kernel: {top_row['kernel']}, C: {top_row['C']}, Weight: {top_row['weight']}, Gamma: {top_row['gamma']}, PCA: {top_row['pca']}\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"Warning: No valid results for seed {seed}\")\n",
    "        print()\n",
    "\n",
    "results_dict[score] = pd.DataFrame(results).sort_values(by=column, ascending=False)\n",
    "\n",
    "# Display the latest concatenated results for this score\n",
    "print(f\"Displaying all results for {score}:\")\n",
    "display(results_dict[score].head(10))  # Shows the latest results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f604df36-aa2f-4fd7-a232-6237ad77fc2e",
   "metadata": {},
   "source": [
    "Running grid search using **precision** as the score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c88591-b6e8-45cd-bce4-eafdd25abb0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "X = df_combined_svc[reduced_svc_features]\n",
    "y = df_combined_svc[\"DiagnosisYN\"]\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'scaler': [StandardScaler()],\n",
    "    'svc__kernel': ['linear', 'rbf', 'poly'],\n",
    "    'svc__class_weight': [None, 'balanced'],\n",
    "    'svc__C': [0.05, 0.1, 1, 10],\n",
    "    'svc__gamma': ['scale', 'auto'],\n",
    "    'pca__n_components': [None, 0.80, 0.90, 6, 7]\n",
    "}\n",
    "\n",
    "#####################################\n",
    "# Choose the score for best_params_ #\n",
    "score = 'precision'\n",
    "#####################################\n",
    "\n",
    "# Choose the column for the final table to sort by\n",
    "column = f'best_{score}'\n",
    "\n",
    "# Name the dataframe that will be created\n",
    "df_name = f\"grid_results_{score}\"\n",
    "\n",
    "# Initialize a list to store results\n",
    "results = []\n",
    "\n",
    "# Loop over 100 random seeds for cross-validation\n",
    "for seed in range(1, 101):\n",
    "    # Print which seed is being used\n",
    "    print(f\"Running with random seed: {seed}\")\n",
    "    \n",
    "    # Run the grid search and get the results\n",
    "    best_params, cv_results_filtered = run_grid_search(X, y, param_grid, score, seed)\n",
    "\n",
    "    # Ensure cv_results_filtered is not empty before accessing .iloc[0]\n",
    "    if not cv_results_filtered.empty:\n",
    "        top_row = cv_results_filtered.iloc[0]\n",
    "    \n",
    "        # Append the best results to the results list\n",
    "        results.append({\n",
    "            'seed': seed,\n",
    "            'kernel': top_row['kernel'],\n",
    "            'C': top_row['C'],\n",
    "            'weight': top_row['weight'],\n",
    "            'gamma': top_row['gamma'],\n",
    "            'pca': top_row['pca'],\n",
    "            'best_accuracy': top_row['accuracy'],\n",
    "            'best_recall': top_row['recall'],\n",
    "            'best_precision': top_row['precision'],\n",
    "            'best_f1': top_row['f1']\n",
    "    })\n",
    "\n",
    "        # Print the best hyperparameters for the current seed\n",
    "        print(f\"Best {score}: {top_row[score]:.4f}, Kernel: {top_row['kernel']}, C: {top_row['C']}, Weight: {top_row['weight']}, Gamma: {top_row['gamma']}, PCA: {top_row['pca']}\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"Warning: No valid results for seed {seed}\")\n",
    "        print()\n",
    "\n",
    "results_dict[score] = pd.DataFrame(results).sort_values(by=column, ascending=False)\n",
    "\n",
    "# Display the latest concatenated results for this score\n",
    "print(f\"Displaying all results for {score}:\")\n",
    "display(results_dict[score].head(10))  # Shows the latest results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b266df-9174-4059-9007-f4cde7501d97",
   "metadata": {},
   "source": [
    "Running grid search using **f1** as the score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a21d62-4a70-45d1-804e-3068b4045de0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "X = df_combined_svc[reduced_svc_features]\n",
    "y = df_combined_svc[\"DiagnosisYN\"]\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'scaler': [StandardScaler()],\n",
    "    'svc__kernel': ['linear', 'rbf', 'poly'],\n",
    "    'svc__class_weight': [None, 'balanced'],\n",
    "    'svc__C': [0.05, 0.1, 1, 10],\n",
    "    'svc__gamma': ['scale', 'auto'],\n",
    "    'pca__n_components': [None, 0.80, 0.90, 6, 7]\n",
    "}\n",
    "\n",
    "#####################################\n",
    "# Choose the score for best_params_ #\n",
    "score = 'f1'\n",
    "#####################################\n",
    "\n",
    "# Choose the column for the final table to sort by\n",
    "column = f'best_{score}'\n",
    "\n",
    "# Name the dataframe that will be created\n",
    "df_name = f\"grid_results_{score}\"\n",
    "\n",
    "# Initialize a list to store results\n",
    "results = []\n",
    "\n",
    "# Loop over 100 random seeds for cross-validation\n",
    "for seed in range(1, 101):\n",
    "    # Print which seed is being used\n",
    "    print(f\"Running with random seed: {seed}\")\n",
    "    \n",
    "    # Run the grid search and get the results\n",
    "    best_params, cv_results_filtered = run_grid_search(X, y, param_grid, score, seed)\n",
    "\n",
    "    # Ensure cv_results_filtered is not empty before accessing .iloc[0]\n",
    "    if not cv_results_filtered.empty:\n",
    "        top_row = cv_results_filtered.iloc[0]\n",
    "    \n",
    "        # Append the best results to the results list\n",
    "        results.append({\n",
    "            'seed': seed,\n",
    "            'kernel': top_row['kernel'],\n",
    "            'C': top_row['C'],\n",
    "            'weight': top_row['weight'],\n",
    "            'gamma': top_row['gamma'],\n",
    "            'pca': top_row['pca'],\n",
    "            'best_accuracy': top_row['accuracy'],\n",
    "            'best_recall': top_row['recall'],\n",
    "            'best_precision': top_row['precision'],\n",
    "            'best_f1': top_row['f1']\n",
    "    })\n",
    "\n",
    "        # Print the best hyperparameters for the current seed\n",
    "        print(f\"Best {score}: {top_row[score]:.4f}, Kernel: {top_row['kernel']}, C: {top_row['C']}, Weight: {top_row['weight']}, Gamma: {top_row['gamma']}, PCA: {top_row['pca']}\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"Warning: No valid results for seed {seed}\")\n",
    "        print()\n",
    "\n",
    "results_dict[score] = pd.DataFrame(results).sort_values(by=column, ascending=False)\n",
    "\n",
    "# Display the latest concatenated results for this score\n",
    "print(f\"Displaying all results for {score}:\")\n",
    "display(results_dict[score].head(10))  # Shows the latest results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ea0cdb-5288-4b04-a7ca-6c30a06109f7",
   "metadata": {},
   "source": [
    "## 6. Final Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89c6662-6fed-4631-b983-b35f7f8afe56",
   "metadata": {},
   "source": [
    "### 6.1 Final 1 // linear // weight balanced // C 10 // gamma scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2b5d28-f3e8-44e2-892b-174ef8b17484",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define feature set and target variable\n",
    "X = df_combined_svc[reduced_svc_features]\n",
    "y = df_combined_svc[\"DiagnosisYN\"]\n",
    "\n",
    "# Store results for each seed\n",
    "results = []\n",
    "\n",
    "# Loop through 500 different random seeds\n",
    "for seed in range(1, 501):\n",
    "    print(f\"Running with seed: {seed}\")\n",
    "    \n",
    "    # Define pipeline: StandardScaler + SVC with predefined parameters\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),  \n",
    "        ('svc', SVC(kernel='linear', class_weight='balanced', C=10, gamma='scale'))\n",
    "    ])\n",
    "    \n",
    "    # Perform 5-fold stratified cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "    # Evaluate model performance using multiple metrics\n",
    "    scores = cross_validate(\n",
    "        pipeline, X, y, cv=skf, \n",
    "        scoring=['accuracy', 'recall', 'precision', 'f1'],\n",
    "        return_train_score=False\n",
    "    )\n",
    "\n",
    "    # Compute mean scores across folds\n",
    "    mean_accuracy = scores['test_accuracy'].mean()\n",
    "    mean_recall = scores['test_recall'].mean()\n",
    "    mean_precision = scores['test_precision'].mean()\n",
    "    mean_f1 = scores['test_f1'].mean()\n",
    "\n",
    "    # Display key results\n",
    "    print(f\"Seed {seed} - Accuracy: {mean_accuracy:.4f}, Recall: {mean_recall:.4f}\")\n",
    "\n",
    "    # Append results to list\n",
    "    results.append([seed, mean_accuracy, mean_recall, mean_precision, mean_f1])\n",
    "\n",
    "# Convert results list to DataFrame\n",
    "linear_10_balanced_scale_nopca = pd.DataFrame(results, columns=['Seed', 'Accuracy', 'Recall', 'Precision', 'F1'])\n",
    "\n",
    "# Display final DataFrame\n",
    "linear_10_balanced_scale_nopca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3280efc2-7475-460d-b070-d1f84aa5ef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only relevant performance metrics\n",
    "linear_10_balanced_scale_nopca = linear_10_balanced_scale_nopca.filter(['Accuracy', 'Recall', 'Precision', 'F1'], axis=1)\n",
    "\n",
    "# Compute mean values for each metric\n",
    "linear_10_balanced_scale_nopca_means = linear_10_balanced_scale_nopca.mean()\n",
    "print(\"Summary of Results:\")\n",
    "print(linear_10_balanced_scale_nopca_means)\n",
    "\n",
    "# Reshape data for visualization\n",
    "linear_10_balanced_scale_nopca_melted = pd.melt(linear_10_balanced_scale_nopca, var_name=\"Metric\", value_name=\"Score\")\n",
    "\n",
    "# Create boxplot to visualize distribution of metric scores\n",
    "plt.figure(figsize=(3, 4))\n",
    "sns.boxplot(\n",
    "    data=linear_10_balanced_scale_nopca_melted,\n",
    "    x=\"Metric\",\n",
    "    y=\"Score\",\n",
    "    hue=\"Metric\",\n",
    "    palette=\"Set2\",\n",
    "    showmeans=True\n",
    ")\n",
    "\n",
    "# Set plot titles and labels\n",
    "plt.title(\"Metric Scores for Final \\nSVC Model Over 500 \\nRandom States\", fontsize=10, fontweight='bold')\n",
    "plt.xlabel(\"Metric\", fontsize=12)\n",
    "plt.ylabel(\"Score\", fontsize=10)\n",
    "plt.ylim(0.7, 0.9)\n",
    "\n",
    "# Adjust x-axis labels\n",
    "plt.xticks(\n",
    "    ticks=[0, 1, 2, 3], \n",
    "    labels=['Accuracy', 'Recall', 'Precision', 'F1'],\n",
    "    fontsize=8\n",
    ")\n",
    "\n",
    "# Remove legend\n",
    "plt.legend([], [], frameon=False)\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(left=0.25)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615f6f8d-5dcf-4fd7-ae9a-84867ff6aa31",
   "metadata": {},
   "source": [
    "### 6.2 Final 2 // poly // C 1 // PCA 6 // gamma auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1083089-aa2d-48c5-8889-1c295d890f39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define feature set and target variable\n",
    "X = df_combined_svc[reduced_svc_features]\n",
    "y = df_combined_svc[\"DiagnosisYN\"]\n",
    "\n",
    "# Store results for each seed\n",
    "results = []\n",
    "\n",
    "# Loop through 500 different random seeds\n",
    "for seed in range(1, 501):\n",
    "    print(f\"Running with seed: {seed}\")\n",
    "    \n",
    "    # Define pipeline: StandardScaler + PCA (6 components) + SVC with predefined parameters\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),  \n",
    "        ('pca', PCA(n_components=6)),  \n",
    "        ('svc', SVC(kernel='poly', class_weight=None, C=1, gamma='auto'))\n",
    "    ])\n",
    "    \n",
    "    # Perform 5-fold stratified cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "    # Evaluate model performance using multiple metrics\n",
    "    scores = cross_validate(\n",
    "        pipeline, X, y, cv=skf, \n",
    "        scoring=['accuracy', 'recall', 'precision', 'f1'],\n",
    "        return_train_score=False\n",
    "    )\n",
    "\n",
    "    # Compute mean scores across folds\n",
    "    mean_accuracy = scores['test_accuracy'].mean()\n",
    "    mean_recall = scores['test_recall'].mean()\n",
    "    mean_precision = scores['test_precision'].mean()\n",
    "    mean_f1 = scores['test_f1'].mean()\n",
    "\n",
    "    # Display key results\n",
    "    print(f\"Seed {seed} - Accuracy: {mean_accuracy:.4f}, Recall: {mean_recall:.4f}\")\n",
    "\n",
    "    # Append results to list\n",
    "    results.append([seed, mean_accuracy, mean_recall, mean_precision, mean_f1])\n",
    "\n",
    "# Convert results list to DataFrame\n",
    "poly_1_none_auto_pca6 = pd.DataFrame(results, columns=['Seed', 'Accuracy', 'Recall', 'Precision', 'F1'])\n",
    "\n",
    "# Display final DataFrame\n",
    "poly_1_none_auto_pca6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708b50fa-b55e-4df5-8ea4-a2eacd0b0a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only relevant performance metrics\n",
    "poly_1_none_auto_pca6 = poly_1_none_auto_pca6.filter(['Accuracy', 'Recall', 'Precision', 'F1'], axis=1)\n",
    "\n",
    "# Compute mean values for each metric\n",
    "poly_1_none_auto_pca6_means = poly_1_none_auto_pca6.mean()\n",
    "print(\"Summary of Results:\")\n",
    "print(poly_1_none_auto_pca6_means)\n",
    "\n",
    "# Reshape data for visualization\n",
    "poly_1_none_auto_pca6_melted = pd.melt(poly_1_none_auto_pca6, var_name=\"Metric\", value_name=\"Score\")\n",
    "\n",
    "# Create boxplot to visualize distribution of metric scores\n",
    "plt.figure(figsize=(3, 4))\n",
    "sns.boxplot(\n",
    "    data=poly_1_none_auto_pca6_melted,\n",
    "    x=\"Metric\",\n",
    "    y=\"Score\",\n",
    "    hue=\"Metric\",\n",
    "    palette=\"Set2\",\n",
    "    showmeans=True\n",
    ")\n",
    "\n",
    "# Set plot titles and labels\n",
    "plt.title(\"Metric Scores for Final \\nSVC Model Over 500 \\nRandom States\", fontsize=10, fontweight='bold')\n",
    "plt.xlabel(\"Metric\", fontsize=12)\n",
    "plt.ylabel(\"Score\", fontsize=10)\n",
    "plt.ylim(0.7, 0.9)\n",
    "\n",
    "# Adjust x-axis labels\n",
    "plt.xticks(\n",
    "    ticks=[0, 1, 2, 3], \n",
    "    labels=['Accuracy', 'Recall', 'Precision', 'F1'],\n",
    "    fontsize=8\n",
    ")\n",
    "\n",
    "# Remove legend\n",
    "plt.legend([], [], frameon=False)\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(left=0.25)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7f3e14-39c1-4585-8bfe-25e97bf41921",
   "metadata": {},
   "source": [
    "### 6.3 Final 3 // rbf // C 1 // gamma scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe1f0ec-a4af-4244-bd79-b8b4ef26c7c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define feature set and target variable\n",
    "X = df_combined_svc[reduced_svc_features]\n",
    "y = df_combined_svc[\"DiagnosisYN\"]\n",
    "\n",
    "# Store results for each seed\n",
    "results = []\n",
    "\n",
    "# Loop through 500 different random seeds\n",
    "for seed in range(1, 501):\n",
    "    print(f\"Running with seed: {seed}\")\n",
    "    \n",
    "    # Define pipeline: StandardScaler + SVC with predefined parameters\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),  \n",
    "        ('svc', SVC(kernel='rbf', class_weight=None, C=1, gamma='scale'))\n",
    "    ])\n",
    "    \n",
    "    # Perform 5-fold stratified cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "    # Evaluate model performance using multiple metrics\n",
    "    scores = cross_validate(\n",
    "        pipeline, X, y, cv=skf, \n",
    "        scoring=['accuracy', 'recall', 'precision', 'f1'],\n",
    "        return_train_score=False\n",
    "    )\n",
    "\n",
    "    # Compute mean scores across folds\n",
    "    mean_accuracy = scores['test_accuracy'].mean()\n",
    "    mean_recall = scores['test_recall'].mean()\n",
    "    mean_precision = scores['test_precision'].mean()\n",
    "    mean_f1 = scores['test_f1'].mean()\n",
    "\n",
    "    # Display key results\n",
    "    print(f\"Seed {seed} - Accuracy: {mean_accuracy:.4f}, Recall: {mean_recall:.4f}\")\n",
    "\n",
    "    # Append results to list\n",
    "    results.append([seed, mean_accuracy, mean_recall, mean_precision, mean_f1])\n",
    "\n",
    "# Convert results list to DataFrame\n",
    "rbf_1_scale_nopca = pd.DataFrame(results, columns=['Seed', 'Accuracy', 'Recall', 'Precision', 'F1'])\n",
    "\n",
    "# Display final DataFrame\n",
    "rbf_1_scale_nopca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66c8b76-def6-4375-ae67-dc7260c8cc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only relevant performance metrics\n",
    "rbf_1_scale_nopca = rbf_1_scale_nopca.filter(['Accuracy', 'Recall', 'Precision', 'F1'], axis=1)\n",
    "\n",
    "# Compute mean values for each metric\n",
    "rbf_1_scale_nopca_means = rbf_1_scale_nopca.mean()\n",
    "print(\"Summary of Results:\")\n",
    "print(rbf_1_scale_nopca_means)\n",
    "\n",
    "# Reshape data for visualization\n",
    "rbf_1_scale_nopca_melted = pd.melt(rbf_1_scale_nopca, var_name=\"Metric\", value_name=\"Score\")\n",
    "\n",
    "# Create boxplot to visualize distribution of metric scores\n",
    "plt.figure(figsize=(3, 4))\n",
    "sns.boxplot(\n",
    "    data=rbf_1_scale_nopca_melted,\n",
    "    x=\"Metric\",\n",
    "    y=\"Score\",\n",
    "    hue=\"Metric\",\n",
    "    palette=\"Set2\",\n",
    "    showmeans=True\n",
    ")\n",
    "\n",
    "# Set plot titles and labels\n",
    "plt.title(\"Metric Scores for Final \\nSVC Model Over 500 \\nRandom States\", fontsize=10, fontweight='bold')\n",
    "plt.xlabel(\"Metric\", fontsize=12)\n",
    "plt.ylabel(\"Score\", fontsize=10)\n",
    "plt.ylim(0.7, 0.9)\n",
    "\n",
    "# Adjust x-axis labels\n",
    "plt.xticks(\n",
    "    ticks=[0, 1, 2, 3], \n",
    "    labels=['Accuracy', 'Recall', 'Precision', 'F1'],\n",
    "    fontsize=8\n",
    ")\n",
    "\n",
    "# Remove legend\n",
    "plt.legend([], [], frameon=False)\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(left=0.25)\n",
    "\n",
    "# Save and show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6904bb-e983-47b6-af1d-33407dd0c47a",
   "metadata": {},
   "source": [
    "### 6.4 Final 4 // rbf // gamma auto // C 0.05 // balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4b2ee5-dd71-404e-856e-1d0010619aa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define feature set and target variable\n",
    "X = df_combined_svc[reduced_svc_features]\n",
    "y = df_combined_svc[\"DiagnosisYN\"]\n",
    "\n",
    "# Store results for each seed\n",
    "results = []\n",
    "\n",
    "# Loop through 500 different random seeds\n",
    "for seed in range(1, 501):\n",
    "    print(f\"Running with seed: {seed}\")\n",
    "    \n",
    "    # Define pipeline: StandardScaler + PCA (6 components) + SVC with predefined parameters\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),  \n",
    "        ('pca', PCA(n_components=6)),  \n",
    "        ('svc', SVC(kernel='rbf', class_weight='balanced', C=0.05, gamma='auto'))\n",
    "    ])\n",
    "    \n",
    "    # Perform 5-fold stratified cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "    # Evaluate model performance using multiple metrics\n",
    "    scores = cross_validate(\n",
    "        pipeline, X, y, cv=skf, \n",
    "        scoring=['accuracy', 'recall', 'precision', 'f1'],\n",
    "        return_train_score=False\n",
    "    )\n",
    "\n",
    "    # Compute mean scores across folds\n",
    "    mean_accuracy = scores['test_accuracy'].mean()\n",
    "    mean_recall = scores['test_recall'].mean()\n",
    "    mean_precision = scores['test_precision'].mean()\n",
    "    mean_f1 = scores['test_f1'].mean()\n",
    "\n",
    "    # Display key results\n",
    "    print(f\"Seed {seed} - Accuracy: {mean_accuracy:.4f}, Recall: {mean_recall:.4f}\")\n",
    "\n",
    "    # Append results to list\n",
    "    results.append([seed, mean_accuracy, mean_recall, mean_precision, mean_f1])\n",
    "\n",
    "# Convert results list to DataFrame\n",
    "rbf_005_balanced_pca6_auto = pd.DataFrame(results, columns=['Seed', 'Accuracy', 'Recall', 'Precision', 'F1'])\n",
    "\n",
    "# Display final DataFrame\n",
    "rbf_005_balanced_pca6_auto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cc0ed9-53b2-43cd-a6ef-6a37ccaa557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only relevant performance metrics\n",
    "rbf_005_balanced_pca6_auto = rbf_005_balanced_pca6_auto.filter(['Accuracy', 'Recall', 'Precision', 'F1'], axis=1)\n",
    "\n",
    "# Compute mean values for each metric\n",
    "rbf_005_balanced_pca6_auto_means = rbf_005_balanced_pca6_auto.mean()\n",
    "print(\"Summary of Results:\")\n",
    "print(rbf_005_balanced_pca6_auto_means)\n",
    "\n",
    "# Reshape data for visualization\n",
    "rbf_005_balanced_pca6_auto_melted = pd.melt(rbf_005_balanced_pca6_auto, var_name=\"Metric\", value_name=\"Score\")\n",
    "\n",
    "# Create boxplot to visualize distribution of metric scores\n",
    "plt.figure(figsize=(3, 4))\n",
    "sns.boxplot(\n",
    "    data=rbf_005_balanced_pca6_auto_melted,\n",
    "    x=\"Metric\",\n",
    "    y=\"Score\",\n",
    "    hue=\"Metric\",\n",
    "    palette=\"Set2\",\n",
    "    showmeans=True\n",
    ")\n",
    "\n",
    "# Set plot titles and labels\n",
    "plt.title(\"Metric Scores for Final \\nSVC Model Over 500 \\nRandom States\", fontsize=10, fontweight='bold')\n",
    "plt.xlabel(\"Metric\", fontsize=12)\n",
    "plt.ylabel(\"Score\", fontsize=10)\n",
    "plt.ylim(0.65, 1.0)\n",
    "\n",
    "# Adjust x-axis labels\n",
    "plt.xticks(\n",
    "    ticks=[0, 1, 2, 3], \n",
    "    labels=['Accuracy', 'Recall', 'Precision', 'F1'],\n",
    "    fontsize=8\n",
    ")\n",
    "\n",
    "# Remove legend\n",
    "plt.legend([], [], frameon=False)\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(left=0.25)\n",
    "\n",
    "# Save and show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8200ca-cc9d-489b-89ff-f92f69203eff",
   "metadata": {},
   "source": [
    "## 7. Confusion Matrix & ROC AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d6856e-45e2-45fb-80b4-3942be6f7b54",
   "metadata": {},
   "source": [
    "Create a confusion matrix using top parameters and random_state 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883751b5-b4ab-4106-8f03-cb3e48f62e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature set and target variable\n",
    "X = df_combined_svc[reduced_svc_features]\n",
    "y = df_combined_svc[\"DiagnosisYN\"]\n",
    "\n",
    "# Split dataset into training and test sets (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train SVC model with predefined parameters\n",
    "model = SVC(kernel=\"linear\", class_weight='balanced', C=10, gamma='scale', probability=True)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Generate predictions on test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix as heatmap\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Negative', 'Positive'], \n",
    "            yticklabels=['Negative', 'Positive'], \n",
    "            cbar=False)\n",
    "\n",
    "# Set plot titles and labels\n",
    "plt.title('Confusion Matrix', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.ylabel('Actual', fontsize=12)\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.subplots_adjust(left=0.2)\n",
    "\n",
    "# Save and display confusion matrix\n",
    "plt.savefig(\"images/Confusion_Matrix.png\")\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91a8844-bb79-46e2-8300-8b727a3106b7",
   "metadata": {},
   "source": [
    "Create a ROC AUC diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a84890e-e499-429b-bcd3-a05aeede37ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities for the test set\n",
    "y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Compute ROC curve values: false positive rate (FPR) and true positive rate (TPR)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "\n",
    "# Calculate the area under the ROC curve (AUC)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# Plot ROC Curve\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "\n",
    "# Add diagonal reference line (random classifier)\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "\n",
    "# Set plot titles and labels\n",
    "plt.title('ROC Curve', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('False Positive Rate', fontsize=10)\n",
    "plt.ylabel('True Positive Rate', fontsize=10)\n",
    "\n",
    "# Configure legend and grid\n",
    "plt.legend(loc='lower right', fontsize=8)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Save and display ROC curve\n",
    "plt.savefig(\"images/ROC_Curve.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ad92f4-695f-4283-a37a-805d28bf6c60",
   "metadata": {},
   "source": [
    "## 8. Reload dataset after removing columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a40756a-8b70-41c5-9cf0-4872f042e793",
   "metadata": {},
   "source": [
    "### 8.1 Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5c576a-3543-40df-a2a1-42ae2f3292fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading csvs into DFs\n",
    "df_cleveland_new = pd.read_csv(\"processed.cleveland.data\",na_values=[\" \",\"?\",\"NA\"],encoding = \"ISO-8859-1\", header=None, delimiter=\",\")\n",
    "df_hungarian_new = pd.read_csv(\"processed.hungarian.data\",na_values=[\" \",\"?\",\"NA\"],encoding = \"ISO-8859-1\", header=None, delimiter=\",\")\n",
    "df_switzerland_new = pd.read_csv(\"processed.switzerland.data\",na_values=[\" \",\"?\",\"NA\"],encoding = \"ISO-8859-1\", header=None, delimiter=\",\")\n",
    "df_longbeach_new = pd.read_csv(\"processed.va.data\",na_values=[\" \",\"?\",\"NA\"],encoding = \"ISO-8859-1\", header=None, delimiter=\",\")\n",
    "\n",
    "# Creating new dictionary of names and dataframes\n",
    "df_all_new_datasets_dict = {\n",
    "    \"Cleveland\": df_cleveland_new, \n",
    "    \"Hungarian\": df_hungarian_new,\n",
    "    \"Switzerland\": df_switzerland_new, \n",
    "    \"Longbeach\": df_longbeach_new\n",
    "}\n",
    "\n",
    "# Creating new column name list and updating names in each dataset\n",
    "new_column_names = [\n",
    "    \"Age\",\n",
    "    \"Sex\",\n",
    "    \"ChestPain\",\n",
    "    \"RestingBP\",\n",
    "    \"Chol\",\n",
    "    \"FastingBS\",\n",
    "    \"RestingECG\",\n",
    "    \"HeartRateMax\",\n",
    "    \"ExeAngina\",\n",
    "    \"STDep\",\n",
    "    \"STSlope\",\n",
    "    \"ColouredMV\",\n",
    "    \"Thalass\",\n",
    "    \"Diagnosis\"\n",
    "]\n",
    "for name, frame in df_all_new_datasets_dict.items():\n",
    "    frame.columns = new_column_names\n",
    "\n",
    "# Dropping columns from datasets\n",
    "for name, frame in df_all_new_datasets_dict.items():   \n",
    "    frame.drop(columns=[\n",
    "        \"FastingBS\",\n",
    "        \"RestingECG\",\n",
    "        \"STSlope\",\n",
    "        \"ColouredMV\"\n",
    "    ], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6ee92b-2bc8-4295-a4f7-289e34a0cccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarise null values in each column for all datasets\n",
    "null_summary_list = [\n",
    "    pd.DataFrame(frame.isna().sum(), columns=[name]) \n",
    "    for name, frame in df_all_new_datasets_dict.items()\n",
    "]\n",
    "\n",
    "# Combine null value summaries into a single DataFrame\n",
    "df_null_summary = pd.concat(null_summary_list, axis=1)\n",
    "\n",
    "# Save null summary to CSV for further analysis\n",
    "df_null_summary.to_csv(\"UCI_location_new_nulls.csv\", index=True)\n",
    "\n",
    "# Display null counts for selected key columns across all datasets\n",
    "df_null_summary.loc[\n",
    "    [\"Age\", \"Sex\", \"ChestPain\", \"RestingBP\", \"Chol\", \n",
    "     \"HeartRateMax\", \"ExeAngina\", \"STDep\", \"Thalass\", \"Diagnosis\"]\n",
    "].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01949830-9a64-467b-addb-719343b2aea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'Location' column to each dataset\n",
    "for name, frame in df_all_new_datasets_dict.items():\n",
    "    frame[\"Location\"] = name  # Assign dataset name as location\n",
    "\n",
    "# Combine all datasets into a single DataFrame\n",
    "df_combined_again = pd.concat(df_all_new_datasets_dict.values(), ignore_index=True)\n",
    "print(\"Shape before dropping NAs:\", df_combined_again.shape)\n",
    "\n",
    "# Drop rows with missing values\n",
    "df_combined_again = df_combined_again.dropna()\n",
    "print(\"Shape after dropping NAs:\", df_combined_again.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9caa2b7-d6c3-45a2-ad97-6eaee75d20d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count remaining rows for each dataset after dropping NAs\n",
    "location_count_list = [\n",
    "    (name, df_combined_again[df_combined_again[\"Location\"] == name].shape[0])\n",
    "    for name in df_all_new_datasets_dict.keys()\n",
    "]\n",
    "\n",
    "# Create a DataFrame to display counts per dataset\n",
    "df_location_count = pd.DataFrame(location_count_list, columns=[\"DataFrame\", \"NoNulls\"]).style.hide(axis=\"index\")\n",
    "df_location_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8b1314-8a54-4133-8c80-23585d1b2b7e",
   "metadata": {},
   "source": [
    "### 8.2 Making Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c293b84e-ead0-41d7-8be5-363aaee43046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply one-hot encoding to categorical features \"ChestPain\" and \"Thalass\"\n",
    "df_combined_again = pd.get_dummies(\n",
    "    df_combined_again, \n",
    "    columns=[\"ChestPain\", \"Thalass\"], \n",
    "    drop_first=False  # Keep all categories to retain full information\n",
    ")\n",
    "\n",
    "# Display the data types of all columns after encoding\n",
    "df_combined_again.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289508ff-9405-4801-a15f-6774de25d8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert \"Diagnosis\" into a binary outcome: \n",
    "# 1 if Diagnosis is in {1, 2, 3, 4} (indicating heart disease), else 0 (no heart disease)\n",
    "df_combined_again[\"DiagnosisYN\"] = np.where(\n",
    "    df_combined_again[\"Diagnosis\"].isin([1, 2, 3, 4]), 1, 0\n",
    ")\n",
    "\n",
    "# Convert \"DiagnosisYN\" to a categorical type with explicit categories\n",
    "df_combined_again[\"DiagnosisYN\"] = pd.Categorical(\n",
    "    df_combined_again[\"DiagnosisYN\"], categories=[0, 1], ordered=False\n",
    ")\n",
    "\n",
    "# Ensure appropriate data types for numerical and boolean columns\n",
    "df_combined_again = df_combined_again.astype({\n",
    "    \"Age\": \"int64\",\n",
    "    \"Sex\": \"bool\",               # Convert Sex to boolean (Male/Female)\n",
    "    \"RestingBP\": \"int64\",\n",
    "    \"Chol\": \"int64\",\n",
    "    \"HeartRateMax\": \"int64\",\n",
    "    \"ExeAngina\": \"bool\",         # Convert Exercise Angina to boolean\n",
    "    \"STDep\": \"float64\",\n",
    "    \"DiagnosisYN\": \"bool\"        # Ensure DiagnosisYN is boolean\n",
    "})\n",
    "\n",
    "# Display updated data types\n",
    "df_combined_again.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adf0430-84f9-4bbe-bdce-b0b3a0073abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define selected features for the SVC model\n",
    "reduced_svc_features = [\n",
    "    \"Age\",\n",
    "    \"Sex\",\n",
    "    \"ChestPain_2.0\",\n",
    "    \"ChestPain_4.0\",\n",
    "    \"RestingBP\",\n",
    "    \"Chol\",\n",
    "    \"HeartRateMax\",\n",
    "    \"ExeAngina\",\n",
    "    \"STDep\",\n",
    "    \"Thalass_3.0\",\n",
    "    \"Thalass_7.0\",\n",
    "]\n",
    "\n",
    "# Define feature matrix (X) and target variable (y)\n",
    "X = df_combined_again[reduced_svc_features]  # Subset dataset using selected features\n",
    "y = df_combined_again[\"DiagnosisYN\"]         # Target variable (heart disease diagnosis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c93fd8b-8032-4346-846f-15b3ccb0dc5a",
   "metadata": {},
   "source": [
    "### 8.3 GridSearchCV with reduced variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc255dd-125d-4658-8fe7-4b406d1a7114",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "X = df_combined_again[reduced_svc_features]\n",
    "y = df_combined_again[\"DiagnosisYN\"]\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'scaler': [StandardScaler()],\n",
    "    'svc__kernel': ['linear', 'rbf', 'poly'],\n",
    "    'svc__class_weight': [None, 'balanced'],\n",
    "    'svc__C': [0.05, 0.1, 1, 10],\n",
    "    'svc__gamma': ['scale', 'auto'],\n",
    "    'pca__n_components': [None, 0.80, 0.90, 6, 7]\n",
    "}\n",
    "\n",
    "#####################################\n",
    "# Choose the score for best_params_ #\n",
    "score = 'accuracy'\n",
    "#####################################\n",
    "\n",
    "# Choose the column for the final table to sort by\n",
    "column = f'best_{score}'\n",
    "\n",
    "# Name the dataframe that will be created\n",
    "df_name = f\"grid_results_{score}\"\n",
    "\n",
    "# Initialize a list to store results\n",
    "results = []\n",
    "\n",
    "# Loop over 100 random seeds for cross-validation\n",
    "for seed in range(1, 101):\n",
    "    # Print which seed is being used\n",
    "    print(f\"Running with random seed: {seed}\")\n",
    "    \n",
    "    # Run the grid search and get the results\n",
    "    best_params, cv_results_filtered = run_grid_search(X, y, param_grid, score, seed)\n",
    "\n",
    "    # Ensure cv_results_filtered is not empty before accessing .iloc[0]\n",
    "    if not cv_results_filtered.empty:\n",
    "        top_row = cv_results_filtered.iloc[0]\n",
    "    \n",
    "        # Append the best results to the results list\n",
    "        results.append({\n",
    "            'seed': seed,\n",
    "            'kernel': top_row['kernel'],\n",
    "            'C': top_row['C'],\n",
    "            'weight': top_row['weight'],\n",
    "            'gamma': top_row['gamma'],\n",
    "            'pca': top_row['pca'],\n",
    "            'best_accuracy': top_row['accuracy'],\n",
    "            'best_recall': top_row['recall'],\n",
    "            'best_precision': top_row['precision'],\n",
    "            'best_f1': top_row['f1']\n",
    "    })\n",
    "\n",
    "        # Print the best hyperparameters for the current seed\n",
    "        print(f\"Best {score}: {top_row[score]:.4f}, Kernel: {top_row['kernel']}, C: {top_row['C']}, Weight: {top_row['weight']}, Gamma: {top_row['gamma']}, PCA: {top_row['pca']}\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"Warning: No valid results for seed {seed}\")\n",
    "        print()\n",
    "\n",
    "results_dict[score] = pd.DataFrame(results).sort_values(by=column, ascending=False)\n",
    "\n",
    "# Display the latest concatenated results for this score\n",
    "print(f\"Displaying all results for {score}:\")\n",
    "display(results_dict[score].head(10))  # Shows the latest results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4284f2-ba00-48fe-9fcd-ac203c1355cb",
   "metadata": {},
   "source": [
    "### 8.4 Supplementary Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee21b58-0544-48ce-867c-912ea4e9d115",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define feature set and target variable\n",
    "X = df_combined_again[reduced_svc_features]\n",
    "y = df_combined_again[\"DiagnosisYN\"]\n",
    "\n",
    "# Store results for each seed\n",
    "results = []\n",
    "\n",
    "# Loop through 500 different random seeds\n",
    "for seed in range(1, 501):\n",
    "    print(f\"Running with seed: {seed}\")\n",
    "    \n",
    "    # Define pipeline: StandardScaler + PCA (6 components) + SVC with predefined parameters\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),  \n",
    "        #('pca', PCA(n_components=6)),  \n",
    "        ('svc', SVC(kernel='rbf', class_weight=None, C=0.05, gamma='scale'))\n",
    "    ])\n",
    "    \n",
    "    # Perform 5-fold stratified cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "    # Evaluate model performance using multiple metrics\n",
    "    scores = cross_validate(\n",
    "        pipeline, X, y, cv=skf, \n",
    "        scoring=['accuracy', 'recall', 'precision', 'f1'],\n",
    "        return_train_score=False\n",
    "    )\n",
    "\n",
    "    # Compute mean scores across folds\n",
    "    mean_accuracy = scores['test_accuracy'].mean()\n",
    "    mean_recall = scores['test_recall'].mean()\n",
    "    mean_precision = scores['test_precision'].mean()\n",
    "    mean_f1 = scores['test_f1'].mean()\n",
    "\n",
    "    # Display key results\n",
    "    print(f\"Seed {seed} - Accuracy: {mean_accuracy:.4f}, Recall: {mean_recall:.4f}\")\n",
    "\n",
    "    # Append results to list\n",
    "    results.append([seed, mean_accuracy, mean_recall, mean_precision, mean_f1])\n",
    "\n",
    "# Convert results list to DataFrame\n",
    "new_model = pd.DataFrame(results, columns=['Seed', 'Accuracy', 'Recall', 'Precision', 'F1'])\n",
    "\n",
    "# Display final DataFrame\n",
    "new_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c51af7f-d3ef-4912-91e2-16ae10d73536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only relevant performance metrics\n",
    "new_model = new_model.filter(['Accuracy', 'Recall', 'Precision', 'F1'], axis=1)\n",
    "\n",
    "# Compute mean values for each metric\n",
    "new_model_means = new_model.mean()\n",
    "print(\"Summary of Results:\")\n",
    "print(new_model_means)\n",
    "\n",
    "# Reshape data for visualization\n",
    "new_model_melted = pd.melt(new_model, var_name=\"Metric\", value_name=\"Score\")\n",
    "\n",
    "# Create boxplot to visualize distribution of metric scores\n",
    "plt.figure(figsize=(3, 4))\n",
    "sns.boxplot(\n",
    "    data=new_model_melted,\n",
    "    x=\"Metric\",\n",
    "    y=\"Score\",\n",
    "    hue=\"Metric\",\n",
    "    palette=\"Set2\",\n",
    "    showmeans=True\n",
    ")\n",
    "\n",
    "# Set plot titles and labels\n",
    "plt.title(\"Metric Scores for Final \\nSVC Model Over 500 \\nRandom States\", fontsize=10, fontweight='bold')\n",
    "plt.xlabel(\"Metric\", fontsize=12)\n",
    "plt.ylabel(\"Score\", fontsize=10)\n",
    "plt.ylim(0.65, 1.0)\n",
    "\n",
    "# Adjust x-axis labels\n",
    "plt.xticks(\n",
    "    ticks=[0, 1, 2, 3], \n",
    "    labels=['Accuracy', 'Recall', 'Precision', 'F1'],\n",
    "    fontsize=8\n",
    ")\n",
    "\n",
    "# Remove legend\n",
    "plt.legend([], [], frameon=False)\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(left=0.25)\n",
    "\n",
    "# Save and show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c06bea2-edc1-405c-bc6b-46a39e3918c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
